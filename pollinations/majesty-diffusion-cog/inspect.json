[
    {
        "Id": "sha256:b8cf2e675991cf79cc0b310d49d43276205c353098466cdc7589cc797caaa180",
        "RepoTags": [
            "614871946825.dkr.ecr.us-east-1.amazonaws.com/pollinations/majesty-diffusion-cog:latest"
        ],
        "RepoDigests": [
            "614871946825.dkr.ecr.us-east-1.amazonaws.com/pollinations/majesty-diffusion-cog@sha256:d211cf0eb979ac747c939511d6d72cfe359255e48e1c86f1c0545b01a34f5482"
        ],
        "Parent": "",
        "Comment": "",
        "Created": "2022-08-03T14:04:20.522481512Z",
        "Container": "1d45fe2c794e34b274da982e7299ca393e845ceb6c42bf937df00affdd972aee",
        "ContainerConfig": {
            "Hostname": "1d45fe2c794e",
            "Domainname": "",
            "User": "",
            "AttachStdin": false,
            "AttachStdout": false,
            "AttachStderr": false,
            "ExposedPorts": {
                "5000/tcp": {}
            },
            "Tty": false,
            "OpenStdin": false,
            "StdinOnce": false,
            "Env": [
                "PATH=/root/.pyenv/shims:/root/.pyenv/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin",
                "NVARCH=x86_64",
                "NVIDIA_REQUIRE_CUDA=cuda>=11.2 brand=tesla,driver>=418,driver<419",
                "NV_CUDA_CUDART_VERSION=11.2.152-1",
                "NV_CUDA_COMPAT_PACKAGE=cuda-compat-11-2",
                "CUDA_VERSION=11.2.2",
                "LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/lib/x86_64-linux-gnu:/usr/local/nvidia/lib64:/usr/local/nvidia/bin",
                "NVIDIA_VISIBLE_DEVICES=all",
                "NVIDIA_DRIVER_CAPABILITIES=compute,utility",
                "NV_CUDA_LIB_VERSION=11.2.2-1",
                "NV_NVTX_VERSION=11.2.152-1",
                "NV_LIBNPP_VERSION=11.3.2.152-1",
                "NV_LIBNPP_PACKAGE=libnpp-11-2=11.3.2.152-1",
                "NV_LIBCUSPARSE_VERSION=11.4.1.1152-1",
                "NV_LIBCUBLAS_PACKAGE_NAME=libcublas-11-2",
                "NV_LIBCUBLAS_VERSION=11.4.1.1043-1",
                "NV_LIBCUBLAS_PACKAGE=libcublas-11-2=11.4.1.1043-1",
                "NV_CUDA_CUDART_DEV_VERSION=11.2.152-1",
                "NV_NVML_DEV_VERSION=11.2.152-1",
                "NV_LIBCUSPARSE_DEV_VERSION=11.4.1.1152-1",
                "NV_LIBNPP_DEV_VERSION=11.3.2.152-1",
                "NV_LIBNPP_DEV_PACKAGE=libnpp-dev-11-2=11.3.2.152-1",
                "NV_LIBCUBLAS_DEV_VERSION=11.4.1.1043-1",
                "NV_LIBCUBLAS_DEV_PACKAGE_NAME=libcublas-dev-11-2",
                "NV_LIBCUBLAS_DEV_PACKAGE=libcublas-dev-11-2=11.4.1.1043-1",
                "NV_NVPROF_VERSION=11.2.152-1",
                "NV_NVPROF_DEV_PACKAGE=cuda-nvprof-11-2=11.2.152-1",
                "LIBRARY_PATH=/usr/local/cuda/lib64/stubs",
                "NV_CUDNN_VERSION=8.1.1.33",
                "NV_CUDNN_PACKAGE=libcudnn8=8.1.1.33-1+cuda11.2",
                "NV_CUDNN_PACKAGE_DEV=libcudnn8-dev=8.1.1.33-1+cuda11.2",
                "NV_CUDNN_PACKAGE_NAME=libcudnn8",
                "DEBIAN_FRONTEND=noninteractive",
                "PYTHONUNBUFFERED=1"
            ],
            "Cmd": [
                "/bin/sh",
                "-c",
                "#(nop) ",
                "LABEL run.cog.version=0.4.0"
            ],
            "ArgsEscaped": true,
            "Image": "sha256:39fdf15600ea27b12d5b04b74a23e59052543b0ea2b542d817b72d2c333286bb",
            "Volumes": null,
            "WorkingDir": "/src",
            "Entrypoint": null,
            "OnBuild": null,
            "Labels": {
                "com.nvidia.cudnn.version": "8.1.1.33",
                "maintainer": "NVIDIA CORPORATION <cudatools@nvidia.com>",
                "org.cogmodel.cog_version": "0.4.0",
                "org.cogmodel.config": "{\"build\":{\"gpu\":true,\"python_version\":\"3.7\",\"python_packages\":[\"numpy==1.21.6\",\"torch==1.11.0\",\"torchvision==0.12.0\",\"omegaconf==2.2.2\",\"pytorch-lightning==1.6.4\",\"torch-fidelity==0.3.0\",\"einops==0.4.1\",\"transformers==4.19.2\",\"open_clip_torch==1.2.1\",\"autokeras==1.0.19\"],\"run\":[\"mkdir -p /content/models/\",\"git clone https://github.com/multimodalart/latent-diffusion --branch 1.6\",\"git clone https://github.com/CompVis/taming-transformers\",\"git clone https://github.com/TencentARC/GFPGAN\",\"curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | bash\",\"apt-get install git-lfs\",\"git lfs install\",\"git lfs clone https://huggingface.co/datasets/multimodalart/latent-majesty-diffusion-settings\",\"git lfs clone https://github.com/LAION-AI/aesthetic-predictor\",\"pip install -e ./taming-transformers\",\"pip install omegaconf\\u003e=2.0.0 pytorch-lightning\\u003e=1.0.8 torch-fidelity einops\",\"pip install transformers\",\"pip install dotmap\",\"pip install resize-right\",\"pip install piq\",\"pip install lpips\",\"pip install basicsr\",\"pip install facexlib\",\"pip install realesrgan\",\"git clone https://github.com/apolinario/Multi-Modal-Comparators --branch gradient_checkpointing\",\"pip install poetry\",\"cd Multi-Modal-Comparators; poetry build; cd ..\",\"cd Multi-Modal-Comparators; pip install dist/mmc*.whl; cd ..\",\"python Multi-Modal-Comparators/src/mmc/napm_installs/__init__.py\",\"wget -O /content/models/latent_diffusion_txt2img_f8_large.ckpt https://ommer-lab.com/files/latent-diffusion/nitro/txt2img-f8-large/model.ckpt --no-check-certificate\",\"wget -O /content/models/txt2img-f8-large-jack000-finetuned-fp16.ckpt https://huggingface.co/multimodalart/compvis-latent-diffusion-text2img-large/resolve/main/txt2img-f8-large-jack000-finetuned-fp16.ckpt --no-check-certificate\",\"wget -O /content/models/ongo.pt https://huggingface.co/laion/ongo/resolve/main/ongo.pt\",\"wget -O /content/models/erlich.pt https://huggingface.co/laion/erlich/resolve/main/model/ema_0.9999_120000.pt\",\"wget -O /content/models/ava_vit_l_14_336_linear.pth https://models.nmb.ai/majesty/ava_vit_l_14_336_linear.pth\",\"wget -O /content/models/sa_0_4_vit_l_14_linear.pth https://models.nmb.ai/majesty/sa_0_4_vit_l_14_linear.pth\",\"wget -O /content/models/ava_vit_l_14_linear.pth https://models.nmb.ai/majesty/ava_vit_l_14_linear.pth\",\"wget -O /content/models/ava_vit_b_16_linear.pth https://the-eye.eu/public/AI/models/v-diffusion/ava_vit_b_16_linear.pth\",\"wget -O /content/models/sa_0_4_vit_b_16_linear.pth https://models.nmb.ai/majesty/sa_0_4_vit_b_16_linear.pth\",\"wget -O /content/models/sa_0_4_vit_b_32_linear.pth https://models.nmb.ai/majesty/sa_0_4_vit_b_32_linear.pth\",\"wget -O /content/models/openimages_512x_png_embed224.npz https://github.com/nshepperd/jax-guided-diffusion/raw/8437b4d390fcc6b57b89cedcbaf1629993c09d03/data/openimages_512x_png_embed224.npz\",\"wget -O /content/models/imagenet_512x_jpg_embed224.npz https://github.com/nshepperd/jax-guided-diffusion/raw/8437b4d390fcc6b57b89cedcbaf1629993c09d03/data/imagenet_512x_jpg_embed224.npz\",\"wget -O /content/models/GFPGANv1.3.pth https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.3.pth\",\"cp /content/models/GFPGANv1.3.pth GFPGAN/experiments/pretrained_models/GFPGANv1.3.pth\"],\"system_packages\":[\"aria2\",\"ffmpeg\"],\"cuda\":\"11.2.2\",\"cudnn\":\"8\"},\"predict\":\"predict.py:Predictor\"}",
                "org.cogmodel.deprecated": "The org.cogmodel labels are deprecated. Use run.cog.",
                "org.cogmodel.openapi_schema": "{\"components\":{\"schemas\":{\"HTTPValidationError\":{\"properties\":{\"detail\":{\"items\":{\"$ref\":\"#/components/schemas/ValidationError\"},\"title\":\"Detail\",\"type\":\"array\"}},\"title\":\"HTTPValidationError\",\"type\":\"object\"},\"Input\":{\"properties\":{\"Prompt\":{\"default\":\"\",\"description\":\"Your text prompt.\",\"title\":\"Prompt\",\"type\":\"string\",\"x-order\":0},\"latent_diffusion_guidance_scale\":{\"default\":12,\"description\":\"Balance between creativity and coherent composition. Try values between 0-15. Lower values help with text interpretation and creativity, higher help with composition. \",\"title\":\"Latent Diffusion Guidance Scale\",\"type\":\"integer\",\"x-order\":2},\"latent_diffusion_model\":{\"allOf\":[{\"$ref\":\"#/components/schemas/latent_diffusion_model\"}],\"default\":\"finetuned\",\"description\":\"Original is the previous LAION model. Finetuned should be better but cannot do text. One of:  [\\\"original\\\", \\\"finetuned\\\", \\\"ongo (fine tuned in paintings)\\\", \\\"erlich (fine tuned in logos)\\\"]\",\"x-order\":1}},\"title\":\"Input\",\"type\":\"object\"},\"Output\":{\"title\":\"Output\",\"type\":\"null\"},\"Request\":{\"description\":\"The request body for a prediction\",\"properties\":{\"input\":{\"$ref\":\"#/components/schemas/Input\"},\"output_file_prefix\":{\"title\":\"Output File Prefix\",\"type\":\"string\"}},\"title\":\"Request\",\"type\":\"object\"},\"Response\":{\"description\":\"The response body for a prediction\",\"properties\":{\"error\":{\"title\":\"Error\",\"type\":\"string\"},\"output\":{\"$ref\":\"#/components/schemas/Output\"},\"status\":{\"$ref\":\"#/components/schemas/Status\"}},\"required\":[\"status\"],\"title\":\"Response\",\"type\":\"object\"},\"Status\":{\"description\":\"An enumeration.\",\"enum\":[\"processing\",\"succeeded\",\"failed\"],\"title\":\"Status\",\"type\":\"string\"},\"ValidationError\":{\"properties\":{\"loc\":{\"items\":{\"anyOf\":[{\"type\":\"string\"},{\"type\":\"integer\"}]},\"title\":\"Location\",\"type\":\"array\"},\"msg\":{\"title\":\"Message\",\"type\":\"string\"},\"type\":{\"title\":\"Error Type\",\"type\":\"string\"}},\"required\":[\"loc\",\"msg\",\"type\"],\"title\":\"ValidationError\",\"type\":\"object\"},\"latent_diffusion_model\":{\"description\":\"An enumeration.\",\"enum\":[\"original\",\"finetuned\",\"ongo (fine tuned in paintings)\",\"erlich (fine tuned in logos)\"],\"title\":\"latent_diffusion_model\",\"type\":\"string\"}}},\"info\":{\"title\":\"Cog\",\"version\":\"0.1.0\"},\"openapi\":\"3.0.2\",\"paths\":{\"/\":{\"get\":{\"operationId\":\"root__get\",\"responses\":{\"200\":{\"content\":{\"application/json\":{\"schema\":{}}},\"description\":\"Successful Response\"}},\"summary\":\"Root\"}},\"/predictions\":{\"post\":{\"description\":\"Run a single prediction on the model\",\"operationId\":\"predict_predictions_post\",\"requestBody\":{\"content\":{\"application/json\":{\"schema\":{\"$ref\":\"#/components/schemas/Request\"}}}},\"responses\":{\"200\":{\"content\":{\"application/json\":{\"schema\":{\"$ref\":\"#/components/schemas/Response\"}}},\"description\":\"Successful Response\"},\"422\":{\"content\":{\"application/json\":{\"schema\":{\"$ref\":\"#/components/schemas/HTTPValidationError\"}}},\"description\":\"Validation Error\"}},\"summary\":\"Predict\"}}}}",
                "run.cog.config": "{\"build\":{\"gpu\":true,\"python_version\":\"3.7\",\"python_packages\":[\"numpy==1.21.6\",\"torch==1.11.0\",\"torchvision==0.12.0\",\"omegaconf==2.2.2\",\"pytorch-lightning==1.6.4\",\"torch-fidelity==0.3.0\",\"einops==0.4.1\",\"transformers==4.19.2\",\"open_clip_torch==1.2.1\",\"autokeras==1.0.19\"],\"run\":[\"mkdir -p /content/models/\",\"git clone https://github.com/multimodalart/latent-diffusion --branch 1.6\",\"git clone https://github.com/CompVis/taming-transformers\",\"git clone https://github.com/TencentARC/GFPGAN\",\"curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | bash\",\"apt-get install git-lfs\",\"git lfs install\",\"git lfs clone https://huggingface.co/datasets/multimodalart/latent-majesty-diffusion-settings\",\"git lfs clone https://github.com/LAION-AI/aesthetic-predictor\",\"pip install -e ./taming-transformers\",\"pip install omegaconf\\u003e=2.0.0 pytorch-lightning\\u003e=1.0.8 torch-fidelity einops\",\"pip install transformers\",\"pip install dotmap\",\"pip install resize-right\",\"pip install piq\",\"pip install lpips\",\"pip install basicsr\",\"pip install facexlib\",\"pip install realesrgan\",\"git clone https://github.com/apolinario/Multi-Modal-Comparators --branch gradient_checkpointing\",\"pip install poetry\",\"cd Multi-Modal-Comparators; poetry build; cd ..\",\"cd Multi-Modal-Comparators; pip install dist/mmc*.whl; cd ..\",\"python Multi-Modal-Comparators/src/mmc/napm_installs/__init__.py\",\"wget -O /content/models/latent_diffusion_txt2img_f8_large.ckpt https://ommer-lab.com/files/latent-diffusion/nitro/txt2img-f8-large/model.ckpt --no-check-certificate\",\"wget -O /content/models/txt2img-f8-large-jack000-finetuned-fp16.ckpt https://huggingface.co/multimodalart/compvis-latent-diffusion-text2img-large/resolve/main/txt2img-f8-large-jack000-finetuned-fp16.ckpt --no-check-certificate\",\"wget -O /content/models/ongo.pt https://huggingface.co/laion/ongo/resolve/main/ongo.pt\",\"wget -O /content/models/erlich.pt https://huggingface.co/laion/erlich/resolve/main/model/ema_0.9999_120000.pt\",\"wget -O /content/models/ava_vit_l_14_336_linear.pth https://models.nmb.ai/majesty/ava_vit_l_14_336_linear.pth\",\"wget -O /content/models/sa_0_4_vit_l_14_linear.pth https://models.nmb.ai/majesty/sa_0_4_vit_l_14_linear.pth\",\"wget -O /content/models/ava_vit_l_14_linear.pth https://models.nmb.ai/majesty/ava_vit_l_14_linear.pth\",\"wget -O /content/models/ava_vit_b_16_linear.pth https://the-eye.eu/public/AI/models/v-diffusion/ava_vit_b_16_linear.pth\",\"wget -O /content/models/sa_0_4_vit_b_16_linear.pth https://models.nmb.ai/majesty/sa_0_4_vit_b_16_linear.pth\",\"wget -O /content/models/sa_0_4_vit_b_32_linear.pth https://models.nmb.ai/majesty/sa_0_4_vit_b_32_linear.pth\",\"wget -O /content/models/openimages_512x_png_embed224.npz https://github.com/nshepperd/jax-guided-diffusion/raw/8437b4d390fcc6b57b89cedcbaf1629993c09d03/data/openimages_512x_png_embed224.npz\",\"wget -O /content/models/imagenet_512x_jpg_embed224.npz https://github.com/nshepperd/jax-guided-diffusion/raw/8437b4d390fcc6b57b89cedcbaf1629993c09d03/data/imagenet_512x_jpg_embed224.npz\",\"wget -O /content/models/GFPGANv1.3.pth https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.3.pth\",\"cp /content/models/GFPGANv1.3.pth GFPGAN/experiments/pretrained_models/GFPGANv1.3.pth\"],\"system_packages\":[\"aria2\",\"ffmpeg\"],\"cuda\":\"11.2.2\",\"cudnn\":\"8\"},\"predict\":\"predict.py:Predictor\"}",
                "run.cog.openapi_schema": "{\"components\":{\"schemas\":{\"HTTPValidationError\":{\"properties\":{\"detail\":{\"items\":{\"$ref\":\"#/components/schemas/ValidationError\"},\"title\":\"Detail\",\"type\":\"array\"}},\"title\":\"HTTPValidationError\",\"type\":\"object\"},\"Input\":{\"properties\":{\"Prompt\":{\"default\":\"\",\"description\":\"Your text prompt.\",\"title\":\"Prompt\",\"type\":\"string\",\"x-order\":0},\"latent_diffusion_guidance_scale\":{\"default\":12,\"description\":\"Balance between creativity and coherent composition. Try values between 0-15. Lower values help with text interpretation and creativity, higher help with composition. \",\"title\":\"Latent Diffusion Guidance Scale\",\"type\":\"integer\",\"x-order\":2},\"latent_diffusion_model\":{\"allOf\":[{\"$ref\":\"#/components/schemas/latent_diffusion_model\"}],\"default\":\"finetuned\",\"description\":\"Original is the previous LAION model. Finetuned should be better but cannot do text. One of:  [\\\"original\\\", \\\"finetuned\\\", \\\"ongo (fine tuned in paintings)\\\", \\\"erlich (fine tuned in logos)\\\"]\",\"x-order\":1}},\"title\":\"Input\",\"type\":\"object\"},\"Output\":{\"title\":\"Output\",\"type\":\"null\"},\"Request\":{\"description\":\"The request body for a prediction\",\"properties\":{\"input\":{\"$ref\":\"#/components/schemas/Input\"},\"output_file_prefix\":{\"title\":\"Output File Prefix\",\"type\":\"string\"}},\"title\":\"Request\",\"type\":\"object\"},\"Response\":{\"description\":\"The response body for a prediction\",\"properties\":{\"error\":{\"title\":\"Error\",\"type\":\"string\"},\"output\":{\"$ref\":\"#/components/schemas/Output\"},\"status\":{\"$ref\":\"#/components/schemas/Status\"}},\"required\":[\"status\"],\"title\":\"Response\",\"type\":\"object\"},\"Status\":{\"description\":\"An enumeration.\",\"enum\":[\"processing\",\"succeeded\",\"failed\"],\"title\":\"Status\",\"type\":\"string\"},\"ValidationError\":{\"properties\":{\"loc\":{\"items\":{\"anyOf\":[{\"type\":\"string\"},{\"type\":\"integer\"}]},\"title\":\"Location\",\"type\":\"array\"},\"msg\":{\"title\":\"Message\",\"type\":\"string\"},\"type\":{\"title\":\"Error Type\",\"type\":\"string\"}},\"required\":[\"loc\",\"msg\",\"type\"],\"title\":\"ValidationError\",\"type\":\"object\"},\"latent_diffusion_model\":{\"description\":\"An enumeration.\",\"enum\":[\"original\",\"finetuned\",\"ongo (fine tuned in paintings)\",\"erlich (fine tuned in logos)\"],\"title\":\"latent_diffusion_model\",\"type\":\"string\"}}},\"info\":{\"title\":\"Cog\",\"version\":\"0.1.0\"},\"openapi\":\"3.0.2\",\"paths\":{\"/\":{\"get\":{\"operationId\":\"root__get\",\"responses\":{\"200\":{\"content\":{\"application/json\":{\"schema\":{}}},\"description\":\"Successful Response\"}},\"summary\":\"Root\"}},\"/predictions\":{\"post\":{\"description\":\"Run a single prediction on the model\",\"operationId\":\"predict_predictions_post\",\"requestBody\":{\"content\":{\"application/json\":{\"schema\":{\"$ref\":\"#/components/schemas/Request\"}}}},\"responses\":{\"200\":{\"content\":{\"application/json\":{\"schema\":{\"$ref\":\"#/components/schemas/Response\"}}},\"description\":\"Successful Response\"},\"422\":{\"content\":{\"application/json\":{\"schema\":{\"$ref\":\"#/components/schemas/HTTPValidationError\"}}},\"description\":\"Validation Error\"}},\"summary\":\"Predict\"}}}}",
                "run.cog.version": "0.4.0"
            }
        },
        "DockerVersion": "20.10.17+azure-1",
        "Author": "",
        "Config": {
            "Hostname": "",
            "Domainname": "",
            "User": "",
            "AttachStdin": false,
            "AttachStdout": false,
            "AttachStderr": false,
            "ExposedPorts": {
                "5000/tcp": {}
            },
            "Tty": false,
            "OpenStdin": false,
            "StdinOnce": false,
            "Env": [
                "PATH=/root/.pyenv/shims:/root/.pyenv/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin",
                "NVARCH=x86_64",
                "NVIDIA_REQUIRE_CUDA=cuda>=11.2 brand=tesla,driver>=418,driver<419",
                "NV_CUDA_CUDART_VERSION=11.2.152-1",
                "NV_CUDA_COMPAT_PACKAGE=cuda-compat-11-2",
                "CUDA_VERSION=11.2.2",
                "LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/lib/x86_64-linux-gnu:/usr/local/nvidia/lib64:/usr/local/nvidia/bin",
                "NVIDIA_VISIBLE_DEVICES=all",
                "NVIDIA_DRIVER_CAPABILITIES=compute,utility",
                "NV_CUDA_LIB_VERSION=11.2.2-1",
                "NV_NVTX_VERSION=11.2.152-1",
                "NV_LIBNPP_VERSION=11.3.2.152-1",
                "NV_LIBNPP_PACKAGE=libnpp-11-2=11.3.2.152-1",
                "NV_LIBCUSPARSE_VERSION=11.4.1.1152-1",
                "NV_LIBCUBLAS_PACKAGE_NAME=libcublas-11-2",
                "NV_LIBCUBLAS_VERSION=11.4.1.1043-1",
                "NV_LIBCUBLAS_PACKAGE=libcublas-11-2=11.4.1.1043-1",
                "NV_CUDA_CUDART_DEV_VERSION=11.2.152-1",
                "NV_NVML_DEV_VERSION=11.2.152-1",
                "NV_LIBCUSPARSE_DEV_VERSION=11.4.1.1152-1",
                "NV_LIBNPP_DEV_VERSION=11.3.2.152-1",
                "NV_LIBNPP_DEV_PACKAGE=libnpp-dev-11-2=11.3.2.152-1",
                "NV_LIBCUBLAS_DEV_VERSION=11.4.1.1043-1",
                "NV_LIBCUBLAS_DEV_PACKAGE_NAME=libcublas-dev-11-2",
                "NV_LIBCUBLAS_DEV_PACKAGE=libcublas-dev-11-2=11.4.1.1043-1",
                "NV_NVPROF_VERSION=11.2.152-1",
                "NV_NVPROF_DEV_PACKAGE=cuda-nvprof-11-2=11.2.152-1",
                "LIBRARY_PATH=/usr/local/cuda/lib64/stubs",
                "NV_CUDNN_VERSION=8.1.1.33",
                "NV_CUDNN_PACKAGE=libcudnn8=8.1.1.33-1+cuda11.2",
                "NV_CUDNN_PACKAGE_DEV=libcudnn8-dev=8.1.1.33-1+cuda11.2",
                "NV_CUDNN_PACKAGE_NAME=libcudnn8",
                "DEBIAN_FRONTEND=noninteractive",
                "PYTHONUNBUFFERED=1"
            ],
            "Cmd": [
                "python",
                "-m",
                "cog.server.http"
            ],
            "ArgsEscaped": true,
            "Image": "sha256:39fdf15600ea27b12d5b04b74a23e59052543b0ea2b542d817b72d2c333286bb",
            "Volumes": null,
            "WorkingDir": "/src",
            "Entrypoint": null,
            "OnBuild": null,
            "Labels": {
                "com.nvidia.cudnn.version": "8.1.1.33",
                "maintainer": "NVIDIA CORPORATION <cudatools@nvidia.com>",
                "org.cogmodel.cog_version": "0.4.0",
                "org.cogmodel.config": "{\"build\":{\"gpu\":true,\"python_version\":\"3.7\",\"python_packages\":[\"numpy==1.21.6\",\"torch==1.11.0\",\"torchvision==0.12.0\",\"omegaconf==2.2.2\",\"pytorch-lightning==1.6.4\",\"torch-fidelity==0.3.0\",\"einops==0.4.1\",\"transformers==4.19.2\",\"open_clip_torch==1.2.1\",\"autokeras==1.0.19\"],\"run\":[\"mkdir -p /content/models/\",\"git clone https://github.com/multimodalart/latent-diffusion --branch 1.6\",\"git clone https://github.com/CompVis/taming-transformers\",\"git clone https://github.com/TencentARC/GFPGAN\",\"curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | bash\",\"apt-get install git-lfs\",\"git lfs install\",\"git lfs clone https://huggingface.co/datasets/multimodalart/latent-majesty-diffusion-settings\",\"git lfs clone https://github.com/LAION-AI/aesthetic-predictor\",\"pip install -e ./taming-transformers\",\"pip install omegaconf\\u003e=2.0.0 pytorch-lightning\\u003e=1.0.8 torch-fidelity einops\",\"pip install transformers\",\"pip install dotmap\",\"pip install resize-right\",\"pip install piq\",\"pip install lpips\",\"pip install basicsr\",\"pip install facexlib\",\"pip install realesrgan\",\"git clone https://github.com/apolinario/Multi-Modal-Comparators --branch gradient_checkpointing\",\"pip install poetry\",\"cd Multi-Modal-Comparators; poetry build; cd ..\",\"cd Multi-Modal-Comparators; pip install dist/mmc*.whl; cd ..\",\"python Multi-Modal-Comparators/src/mmc/napm_installs/__init__.py\",\"wget -O /content/models/latent_diffusion_txt2img_f8_large.ckpt https://ommer-lab.com/files/latent-diffusion/nitro/txt2img-f8-large/model.ckpt --no-check-certificate\",\"wget -O /content/models/txt2img-f8-large-jack000-finetuned-fp16.ckpt https://huggingface.co/multimodalart/compvis-latent-diffusion-text2img-large/resolve/main/txt2img-f8-large-jack000-finetuned-fp16.ckpt --no-check-certificate\",\"wget -O /content/models/ongo.pt https://huggingface.co/laion/ongo/resolve/main/ongo.pt\",\"wget -O /content/models/erlich.pt https://huggingface.co/laion/erlich/resolve/main/model/ema_0.9999_120000.pt\",\"wget -O /content/models/ava_vit_l_14_336_linear.pth https://models.nmb.ai/majesty/ava_vit_l_14_336_linear.pth\",\"wget -O /content/models/sa_0_4_vit_l_14_linear.pth https://models.nmb.ai/majesty/sa_0_4_vit_l_14_linear.pth\",\"wget -O /content/models/ava_vit_l_14_linear.pth https://models.nmb.ai/majesty/ava_vit_l_14_linear.pth\",\"wget -O /content/models/ava_vit_b_16_linear.pth https://the-eye.eu/public/AI/models/v-diffusion/ava_vit_b_16_linear.pth\",\"wget -O /content/models/sa_0_4_vit_b_16_linear.pth https://models.nmb.ai/majesty/sa_0_4_vit_b_16_linear.pth\",\"wget -O /content/models/sa_0_4_vit_b_32_linear.pth https://models.nmb.ai/majesty/sa_0_4_vit_b_32_linear.pth\",\"wget -O /content/models/openimages_512x_png_embed224.npz https://github.com/nshepperd/jax-guided-diffusion/raw/8437b4d390fcc6b57b89cedcbaf1629993c09d03/data/openimages_512x_png_embed224.npz\",\"wget -O /content/models/imagenet_512x_jpg_embed224.npz https://github.com/nshepperd/jax-guided-diffusion/raw/8437b4d390fcc6b57b89cedcbaf1629993c09d03/data/imagenet_512x_jpg_embed224.npz\",\"wget -O /content/models/GFPGANv1.3.pth https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.3.pth\",\"cp /content/models/GFPGANv1.3.pth GFPGAN/experiments/pretrained_models/GFPGANv1.3.pth\"],\"system_packages\":[\"aria2\",\"ffmpeg\"],\"cuda\":\"11.2.2\",\"cudnn\":\"8\"},\"predict\":\"predict.py:Predictor\"}",
                "org.cogmodel.deprecated": "The org.cogmodel labels are deprecated. Use run.cog.",
                "org.cogmodel.openapi_schema": "{\"components\":{\"schemas\":{\"HTTPValidationError\":{\"properties\":{\"detail\":{\"items\":{\"$ref\":\"#/components/schemas/ValidationError\"},\"title\":\"Detail\",\"type\":\"array\"}},\"title\":\"HTTPValidationError\",\"type\":\"object\"},\"Input\":{\"properties\":{\"Prompt\":{\"default\":\"\",\"description\":\"Your text prompt.\",\"title\":\"Prompt\",\"type\":\"string\",\"x-order\":0},\"latent_diffusion_guidance_scale\":{\"default\":12,\"description\":\"Balance between creativity and coherent composition. Try values between 0-15. Lower values help with text interpretation and creativity, higher help with composition. \",\"title\":\"Latent Diffusion Guidance Scale\",\"type\":\"integer\",\"x-order\":2},\"latent_diffusion_model\":{\"allOf\":[{\"$ref\":\"#/components/schemas/latent_diffusion_model\"}],\"default\":\"finetuned\",\"description\":\"Original is the previous LAION model. Finetuned should be better but cannot do text. One of:  [\\\"original\\\", \\\"finetuned\\\", \\\"ongo (fine tuned in paintings)\\\", \\\"erlich (fine tuned in logos)\\\"]\",\"x-order\":1}},\"title\":\"Input\",\"type\":\"object\"},\"Output\":{\"title\":\"Output\",\"type\":\"null\"},\"Request\":{\"description\":\"The request body for a prediction\",\"properties\":{\"input\":{\"$ref\":\"#/components/schemas/Input\"},\"output_file_prefix\":{\"title\":\"Output File Prefix\",\"type\":\"string\"}},\"title\":\"Request\",\"type\":\"object\"},\"Response\":{\"description\":\"The response body for a prediction\",\"properties\":{\"error\":{\"title\":\"Error\",\"type\":\"string\"},\"output\":{\"$ref\":\"#/components/schemas/Output\"},\"status\":{\"$ref\":\"#/components/schemas/Status\"}},\"required\":[\"status\"],\"title\":\"Response\",\"type\":\"object\"},\"Status\":{\"description\":\"An enumeration.\",\"enum\":[\"processing\",\"succeeded\",\"failed\"],\"title\":\"Status\",\"type\":\"string\"},\"ValidationError\":{\"properties\":{\"loc\":{\"items\":{\"anyOf\":[{\"type\":\"string\"},{\"type\":\"integer\"}]},\"title\":\"Location\",\"type\":\"array\"},\"msg\":{\"title\":\"Message\",\"type\":\"string\"},\"type\":{\"title\":\"Error Type\",\"type\":\"string\"}},\"required\":[\"loc\",\"msg\",\"type\"],\"title\":\"ValidationError\",\"type\":\"object\"},\"latent_diffusion_model\":{\"description\":\"An enumeration.\",\"enum\":[\"original\",\"finetuned\",\"ongo (fine tuned in paintings)\",\"erlich (fine tuned in logos)\"],\"title\":\"latent_diffusion_model\",\"type\":\"string\"}}},\"info\":{\"title\":\"Cog\",\"version\":\"0.1.0\"},\"openapi\":\"3.0.2\",\"paths\":{\"/\":{\"get\":{\"operationId\":\"root__get\",\"responses\":{\"200\":{\"content\":{\"application/json\":{\"schema\":{}}},\"description\":\"Successful Response\"}},\"summary\":\"Root\"}},\"/predictions\":{\"post\":{\"description\":\"Run a single prediction on the model\",\"operationId\":\"predict_predictions_post\",\"requestBody\":{\"content\":{\"application/json\":{\"schema\":{\"$ref\":\"#/components/schemas/Request\"}}}},\"responses\":{\"200\":{\"content\":{\"application/json\":{\"schema\":{\"$ref\":\"#/components/schemas/Response\"}}},\"description\":\"Successful Response\"},\"422\":{\"content\":{\"application/json\":{\"schema\":{\"$ref\":\"#/components/schemas/HTTPValidationError\"}}},\"description\":\"Validation Error\"}},\"summary\":\"Predict\"}}}}",
                "run.cog.config": "{\"build\":{\"gpu\":true,\"python_version\":\"3.7\",\"python_packages\":[\"numpy==1.21.6\",\"torch==1.11.0\",\"torchvision==0.12.0\",\"omegaconf==2.2.2\",\"pytorch-lightning==1.6.4\",\"torch-fidelity==0.3.0\",\"einops==0.4.1\",\"transformers==4.19.2\",\"open_clip_torch==1.2.1\",\"autokeras==1.0.19\"],\"run\":[\"mkdir -p /content/models/\",\"git clone https://github.com/multimodalart/latent-diffusion --branch 1.6\",\"git clone https://github.com/CompVis/taming-transformers\",\"git clone https://github.com/TencentARC/GFPGAN\",\"curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | bash\",\"apt-get install git-lfs\",\"git lfs install\",\"git lfs clone https://huggingface.co/datasets/multimodalart/latent-majesty-diffusion-settings\",\"git lfs clone https://github.com/LAION-AI/aesthetic-predictor\",\"pip install -e ./taming-transformers\",\"pip install omegaconf\\u003e=2.0.0 pytorch-lightning\\u003e=1.0.8 torch-fidelity einops\",\"pip install transformers\",\"pip install dotmap\",\"pip install resize-right\",\"pip install piq\",\"pip install lpips\",\"pip install basicsr\",\"pip install facexlib\",\"pip install realesrgan\",\"git clone https://github.com/apolinario/Multi-Modal-Comparators --branch gradient_checkpointing\",\"pip install poetry\",\"cd Multi-Modal-Comparators; poetry build; cd ..\",\"cd Multi-Modal-Comparators; pip install dist/mmc*.whl; cd ..\",\"python Multi-Modal-Comparators/src/mmc/napm_installs/__init__.py\",\"wget -O /content/models/latent_diffusion_txt2img_f8_large.ckpt https://ommer-lab.com/files/latent-diffusion/nitro/txt2img-f8-large/model.ckpt --no-check-certificate\",\"wget -O /content/models/txt2img-f8-large-jack000-finetuned-fp16.ckpt https://huggingface.co/multimodalart/compvis-latent-diffusion-text2img-large/resolve/main/txt2img-f8-large-jack000-finetuned-fp16.ckpt --no-check-certificate\",\"wget -O /content/models/ongo.pt https://huggingface.co/laion/ongo/resolve/main/ongo.pt\",\"wget -O /content/models/erlich.pt https://huggingface.co/laion/erlich/resolve/main/model/ema_0.9999_120000.pt\",\"wget -O /content/models/ava_vit_l_14_336_linear.pth https://models.nmb.ai/majesty/ava_vit_l_14_336_linear.pth\",\"wget -O /content/models/sa_0_4_vit_l_14_linear.pth https://models.nmb.ai/majesty/sa_0_4_vit_l_14_linear.pth\",\"wget -O /content/models/ava_vit_l_14_linear.pth https://models.nmb.ai/majesty/ava_vit_l_14_linear.pth\",\"wget -O /content/models/ava_vit_b_16_linear.pth https://the-eye.eu/public/AI/models/v-diffusion/ava_vit_b_16_linear.pth\",\"wget -O /content/models/sa_0_4_vit_b_16_linear.pth https://models.nmb.ai/majesty/sa_0_4_vit_b_16_linear.pth\",\"wget -O /content/models/sa_0_4_vit_b_32_linear.pth https://models.nmb.ai/majesty/sa_0_4_vit_b_32_linear.pth\",\"wget -O /content/models/openimages_512x_png_embed224.npz https://github.com/nshepperd/jax-guided-diffusion/raw/8437b4d390fcc6b57b89cedcbaf1629993c09d03/data/openimages_512x_png_embed224.npz\",\"wget -O /content/models/imagenet_512x_jpg_embed224.npz https://github.com/nshepperd/jax-guided-diffusion/raw/8437b4d390fcc6b57b89cedcbaf1629993c09d03/data/imagenet_512x_jpg_embed224.npz\",\"wget -O /content/models/GFPGANv1.3.pth https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.3.pth\",\"cp /content/models/GFPGANv1.3.pth GFPGAN/experiments/pretrained_models/GFPGANv1.3.pth\"],\"system_packages\":[\"aria2\",\"ffmpeg\"],\"cuda\":\"11.2.2\",\"cudnn\":\"8\"},\"predict\":\"predict.py:Predictor\"}",
                "run.cog.openapi_schema": "{\"components\":{\"schemas\":{\"HTTPValidationError\":{\"properties\":{\"detail\":{\"items\":{\"$ref\":\"#/components/schemas/ValidationError\"},\"title\":\"Detail\",\"type\":\"array\"}},\"title\":\"HTTPValidationError\",\"type\":\"object\"},\"Input\":{\"properties\":{\"Prompt\":{\"default\":\"\",\"description\":\"Your text prompt.\",\"title\":\"Prompt\",\"type\":\"string\",\"x-order\":0},\"latent_diffusion_guidance_scale\":{\"default\":12,\"description\":\"Balance between creativity and coherent composition. Try values between 0-15. Lower values help with text interpretation and creativity, higher help with composition. \",\"title\":\"Latent Diffusion Guidance Scale\",\"type\":\"integer\",\"x-order\":2},\"latent_diffusion_model\":{\"allOf\":[{\"$ref\":\"#/components/schemas/latent_diffusion_model\"}],\"default\":\"finetuned\",\"description\":\"Original is the previous LAION model. Finetuned should be better but cannot do text. One of:  [\\\"original\\\", \\\"finetuned\\\", \\\"ongo (fine tuned in paintings)\\\", \\\"erlich (fine tuned in logos)\\\"]\",\"x-order\":1}},\"title\":\"Input\",\"type\":\"object\"},\"Output\":{\"title\":\"Output\",\"type\":\"null\"},\"Request\":{\"description\":\"The request body for a prediction\",\"properties\":{\"input\":{\"$ref\":\"#/components/schemas/Input\"},\"output_file_prefix\":{\"title\":\"Output File Prefix\",\"type\":\"string\"}},\"title\":\"Request\",\"type\":\"object\"},\"Response\":{\"description\":\"The response body for a prediction\",\"properties\":{\"error\":{\"title\":\"Error\",\"type\":\"string\"},\"output\":{\"$ref\":\"#/components/schemas/Output\"},\"status\":{\"$ref\":\"#/components/schemas/Status\"}},\"required\":[\"status\"],\"title\":\"Response\",\"type\":\"object\"},\"Status\":{\"description\":\"An enumeration.\",\"enum\":[\"processing\",\"succeeded\",\"failed\"],\"title\":\"Status\",\"type\":\"string\"},\"ValidationError\":{\"properties\":{\"loc\":{\"items\":{\"anyOf\":[{\"type\":\"string\"},{\"type\":\"integer\"}]},\"title\":\"Location\",\"type\":\"array\"},\"msg\":{\"title\":\"Message\",\"type\":\"string\"},\"type\":{\"title\":\"Error Type\",\"type\":\"string\"}},\"required\":[\"loc\",\"msg\",\"type\"],\"title\":\"ValidationError\",\"type\":\"object\"},\"latent_diffusion_model\":{\"description\":\"An enumeration.\",\"enum\":[\"original\",\"finetuned\",\"ongo (fine tuned in paintings)\",\"erlich (fine tuned in logos)\"],\"title\":\"latent_diffusion_model\",\"type\":\"string\"}}},\"info\":{\"title\":\"Cog\",\"version\":\"0.1.0\"},\"openapi\":\"3.0.2\",\"paths\":{\"/\":{\"get\":{\"operationId\":\"root__get\",\"responses\":{\"200\":{\"content\":{\"application/json\":{\"schema\":{}}},\"description\":\"Successful Response\"}},\"summary\":\"Root\"}},\"/predictions\":{\"post\":{\"description\":\"Run a single prediction on the model\",\"operationId\":\"predict_predictions_post\",\"requestBody\":{\"content\":{\"application/json\":{\"schema\":{\"$ref\":\"#/components/schemas/Request\"}}}},\"responses\":{\"200\":{\"content\":{\"application/json\":{\"schema\":{\"$ref\":\"#/components/schemas/Response\"}}},\"description\":\"Successful Response\"},\"422\":{\"content\":{\"application/json\":{\"schema\":{\"$ref\":\"#/components/schemas/HTTPValidationError\"}}},\"description\":\"Validation Error\"}},\"summary\":\"Predict\"}}}}",
                "run.cog.version": "0.4.0"
            }
        },
        "Architecture": "amd64",
        "Os": "linux",
        "Size": 29391487279,
        "VirtualSize": 29391487279,
        "GraphDriver": {
            "Data": {
                "LowerDir": "/var/lib/docker/overlay2/fcb00391e89cc16961bdd0601e580b87b7db65fae9c731a92d2d2041f1198a76/diff:/var/lib/docker/overlay2/80c0fb5a97211d3414c55f9147a1cf0a5f2afe8a7cd0c79ad9cb080356034a1c/diff:/var/lib/docker/overlay2/daa359b5c5295366a1db17a1027c08d660f3094211ffabe9208d2168c295a42e/diff:/var/lib/docker/overlay2/b158265f01ec3b01a3ff9b60982abc47f0dd4d03dd13889eeaf99cda501e1113/diff:/var/lib/docker/overlay2/4b42ebfc2d67625cc260c15108914146c6cdb4f1bb23b4d9d389f2f697dba7b5/diff:/var/lib/docker/overlay2/31ce83fcac9f91f51e806acfcebd3249828fa00cbef73e9764db8f9a95b50984/diff:/var/lib/docker/overlay2/30474bc43bd25a0a426987c13e52a89229bf10223f3ee7ec05a657951305c6e9/diff:/var/lib/docker/overlay2/3b4c841add46ec2dfe9a206e64d721f8d797a9f4505a9e2b49734133186c72f4/diff:/var/lib/docker/overlay2/2b1e142904390a36ec7b1cd9ba3537b99a078edd5eac643f6777eb0e7b2c8e31/diff:/var/lib/docker/overlay2/c21d8a5bf7494d7727ee9ee40e441cfadb8c52efbad8e6c8edba6b4a1ab598ae/diff:/var/lib/docker/overlay2/64b7411fcaa3f3b6f6a248a415b305e858c8118a761c9cc014ddf5608daec5e1/diff:/var/lib/docker/overlay2/b997de63a1778d5379bdcccfeb0a71d72a295669dba204370c4705e5609b80de/diff:/var/lib/docker/overlay2/e6ae7ad414cd612a29901e1ee8ed31cdb6b6ded539d39bcad7e989a12b06ff8a/diff:/var/lib/docker/overlay2/4db98498af46416d80b3fce6cfc3b74d43072ab492cbffdfba0fac856b3d63c9/diff:/var/lib/docker/overlay2/ba45f9b5ae474699cd336aceb22c646493206925f88949684fbfdd21dcb78f3c/diff:/var/lib/docker/overlay2/6da8224557ead2f7a3c5d89589171ef96615f56ac5ddae4043b01b520d50ef52/diff:/var/lib/docker/overlay2/80bf8ff3feb3f419a7d3ad7be5755c2205d29e8ffcba6bf3ed7cc6d7ff7fbaf2/diff:/var/lib/docker/overlay2/e9f65dab6a1ef04d0bf1614c44d0128bb47615ce80214b2431d57842d0bc63be/diff:/var/lib/docker/overlay2/b7f142940079121f363db0c77cdd4e6ebd6d40509ea573f96062a2e6c7f63a33/diff:/var/lib/docker/overlay2/5f4d4d6fdc5ce0adabd2925c08e9e53c7ebc26d1136a9688d98a6619e78f343a/diff:/var/lib/docker/overlay2/c27948b1e453332417b2a96bd54a4690ceb15fe29940c7efd5b041a984110dc0/diff:/var/lib/docker/overlay2/62c4bf51ab532b6b98ccf4c306c3b2ee989671e22403d46197ce52199595487f/diff:/var/lib/docker/overlay2/427562b9d528b962b50744bd3d239616b392eb001f4e752cece8d019dd04595b/diff:/var/lib/docker/overlay2/501df192c54737ccecf20898c3820fef970558b78955511e8a8a89df45e0e5ee/diff:/var/lib/docker/overlay2/4405cf4f9aea743ba3b5aa2680ad4116f4ed993b0e2b3ab0f10e72664d9a2bd0/diff:/var/lib/docker/overlay2/d87ff9947edd2572cddbaac3586cf794af39d88c889bba8d9c98f4f4898d376a/diff:/var/lib/docker/overlay2/f26ddc11718256e9b061e16fe2a8db102b37a52e14ece23f3c91a082da40296e/diff:/var/lib/docker/overlay2/19ce1729bf8afc06606e27a588b88fd84f3825929690edf47c35f3fe48fd780f/diff:/var/lib/docker/overlay2/bf35525c0800792ba8398e3e28b2161ea98ba099ff804e4da85a629c52447b50/diff:/var/lib/docker/overlay2/482c008cbc178ed301ddfe8f3ad72102eba7d3985f28524a9ab0f4b8613b5f62/diff:/var/lib/docker/overlay2/09519cece6febb9cc95cd30768b244bc90bac5bedc15c25199e719f365aed662/diff:/var/lib/docker/overlay2/45ba0acd9c52fe460a4c532532dda3bfb695bd0fa171e8e3dbddb996a3d0d105/diff:/var/lib/docker/overlay2/232f6e1b6730160beb93418e11ee36a5a3e92ca1a1685dfb2568ba2146340628/diff:/var/lib/docker/overlay2/509f33263f52183c5c451b1d2769c03eef223017ef8435c43a2b66c1b8837c75/diff:/var/lib/docker/overlay2/eb0e2cf88a5726a8679b48395119b069e1af25dca4c8bc5fea0696bd6c44aa93/diff:/var/lib/docker/overlay2/13236b57540691c8b808cb26143d9f90395ae5ed49938694d30c80fe742f7ab6/diff:/var/lib/docker/overlay2/503a13309fc9c80737961ea034b4e14bc6d24a5d5b220ebff2f91d79a67a58c6/diff:/var/lib/docker/overlay2/a99f98c0438e6b05de70c6f71417db92420de7db2ef31ea2c5f3ff26c8a17b77/diff:/var/lib/docker/overlay2/b03fc107bcbbf3970ee6067ec9fbf335cc726592f72eab5d6a4b568e9597f054/diff:/var/lib/docker/overlay2/9388de6d022889964706fe7bb3501bac1cf537a0f9b564db9e2deccfecc02c27/diff:/var/lib/docker/overlay2/e5089019ec1ed53164ac43d13a09b5eae10e67258d63188e6da5a9a23fecd069/diff:/var/lib/docker/overlay2/0c8c815e23d21448c54f7a4b2d0ec1ff6dd3bc93d5d5b362e2e39cc735fbcea2/diff:/var/lib/docker/overlay2/0c73d303589ac8529ee281012571354622398197f1943246619b8244d70d5f33/diff:/var/lib/docker/overlay2/4a4e35435c24de12dd78e573da433b2d8454dea0415f0050b41f9537663a95bd/diff:/var/lib/docker/overlay2/5ed4a645c1b701593ea9ee1b52c0bbad690759ff9a6956832bdbb10c281fff0a/diff:/var/lib/docker/overlay2/3f066a1e9c15d91bcedd9de61efed79861a6b8ed473b428dfaa17563f1430f3b/diff:/var/lib/docker/overlay2/d33cb784414fa4c6eaddbc4ab3dcb620e74f57d9bcf69b0ad0a5b57aebb8542c/diff:/var/lib/docker/overlay2/01f4d60ba0891523a1dcb899b262fdce0800a2537ac348dab1783c0262b8d996/diff:/var/lib/docker/overlay2/0ef1821409a93580f740dc912d39de52b15ed3b762f8cd80989c44dc9b156e54/diff:/var/lib/docker/overlay2/8138199d69857c1d96b4e0e9451d08d885ba5032bd0b8ed537d4747754046c12/diff:/var/lib/docker/overlay2/af249269c9bf8ab379688ac10c37b3f80557ae5e37377dc78b4853c4a0aed749/diff:/var/lib/docker/overlay2/5b0d709f9608e33c06bed35653a7fc384f5b310d2cd280920e77682c2eede20c/diff:/var/lib/docker/overlay2/7b35d2db18bf8d52716df1d5dc89fa4fe0b75c55ca4f77be68e64d399853f812/diff:/var/lib/docker/overlay2/6d53a3f6c8dbc35ce010c02eb29876107989b3c7c466245f90e6a161cbc3af99/diff:/var/lib/docker/overlay2/7326a8628275835815d8b795836ed9d5e4da1c5d1828ad8d5b9ca264c79dfe23/diff:/var/lib/docker/overlay2/799fcef6f5fd5ba7434a54cc200600b62be46ddbbd92539d5aaad3e354525418/diff:/var/lib/docker/overlay2/97a9396838d7bd804902cd49965eff5ee7cdba5b016e9f6f186a05af0d631ca9/diff:/var/lib/docker/overlay2/bfa2523624a319d4ecdb4c516b426156fc37a9fdd9f85408d0464db20488e798/diff:/var/lib/docker/overlay2/334304eba9f8bd81019d10575921e39222ad46b859f05107238105a378601a33/diff",
                "MergedDir": "/var/lib/docker/overlay2/371de1862a37203c2d2a39fc65050a676f60993478cadaca8d4af5c2046f8805/merged",
                "UpperDir": "/var/lib/docker/overlay2/371de1862a37203c2d2a39fc65050a676f60993478cadaca8d4af5c2046f8805/diff",
                "WorkDir": "/var/lib/docker/overlay2/371de1862a37203c2d2a39fc65050a676f60993478cadaca8d4af5c2046f8805/work"
            },
            "Name": "overlay2"
        },
        "RootFS": {
            "Type": "layers",
            "Layers": [
                "sha256:be96a3f634de79f523f07c7e4e0216c28af45eb5776e7a6238a2392f71e01069",
                "sha256:df54c846128da3c71cc11b2150a3df39ec86fb170e299765daf6bb016a0705c2",
                "sha256:47ef83afae74745639f6738a05fe5320fcfca9e6c7765fba4f25e270bc0df9dc",
                "sha256:1251204ef8fc20da275e09f6e3ab9205421d4ff34732f2d50a1d3e86d2995edd",
                "sha256:a053d5fbf6214982010835a80f01dd15ba89a6ac6278d92d992ff98a415e23cb",
                "sha256:896120a5709af8bb8dd29dbd61d67bbf6c83ea3e9c6034e5585a00afc625df8d",
                "sha256:6d357a586d6ccd28a63de1569758ef7380ec683ecae91dcb8f05b0f7b235d35e",
                "sha256:3b9d7320fc61ddf0d42916e1fdc9a880cdf5133607cd993ae3a923af4b13d20e",
                "sha256:ad6a695ffdcf3f0517e3f745971d1acd0af7f95bd4a05e4150378999e1439b53",
                "sha256:a93ae153f82719c505090c79fcf8df22ada144f9d613ee5caa46501a90d36f63",
                "sha256:75c6b9b57da528d2ef7c9b26a40d387043e77c42e6bc8a58461fd5bf21ef3f05",
                "sha256:c8f58786c92d7bf9c1bbd54dc3b0267c0b5788702c38675b1a84b4a6b9c2cb89",
                "sha256:9fbd29c4c152460c12fbebd0c67f1c6154b2775d28154de707cff7ac30ef9697",
                "sha256:1d7efc2c8f0f9d66a2970b22c9066d88e3301fe5514b6df2c3902550582db928",
                "sha256:13715645ee31255727d199d8acef1aeaf137938c5c9dd6a4531022f234a1998f",
                "sha256:2890d646fe2714a05d8ad7c7c5e0112d5361925acd4a71e17ff325c190a9fdda",
                "sha256:f213c5242c22e2696b26e3909c893bfa8060dac9893d3067e7cd79270c0f341d",
                "sha256:150cb61e73b4352c40848832662527e115664be3bfa9840f671bf5f8be4e9e73",
                "sha256:2f6bc9fb50d11447c111e9319c20d5ecb5472ab56b196004d32e91928744f35d",
                "sha256:c4b02bc122639e0f3afd2a40ca935201485fdf3c9ddf8a681994000707ffe141",
                "sha256:9a124479462c6fc3351d81b410968c99d978b845204bb59b0202688a7031f09e",
                "sha256:b478792a072b6440db7886f7223fbb3b0a9a033e3f11b034f85e8c05c12331eb",
                "sha256:420cff1d9744638efa1b6810b2db057f6b13074d6354ea34c286552dad5d436d",
                "sha256:eb78a0f38d49ec1676c8556aa96e472964a5c78129d1b99b6df7bf3bd12b1414",
                "sha256:74c179e49161fd5601fd3a71a700869f986b95e332890f1619728a2699e0adad",
                "sha256:8d8f9f5360519c602f00dbcc9655b5d5863ca7bb868f557e6ae73b3243d5caa3",
                "sha256:841e4cccfe92578e3733911c1c3782b81510e83964a4d97aa9f116115fdf35e9",
                "sha256:45b46f8f42c9e331f92974b61651f81a8b44033140ee8316e91ecefdf5f3370c",
                "sha256:7913ba8ad57039928a3920918fd99910de3e073285f5e2086148f321dbc19bcb",
                "sha256:bd8e37fb43eb092cff781c2514545ebc4e36641f6960e98af81d413fbb12b2bf",
                "sha256:6ec446855e77593c7e7cfed8acc2c11f282a42cfeee16807cd7b2f8f323ecdc6",
                "sha256:5f70bf18a086007016e948b04aed3b82103a36bea41755b6cddfaf10ace3c6ef",
                "sha256:f107f8f5827cfcecbec926f57547cdd2fb1b600922e9a90968443977d793ff4e",
                "sha256:463f52e45978fb8c960d174a99717f2ebbc2b1097e12fff55643940009d06780",
                "sha256:a5be4322adc9213d331a59ef93c49fafa73839cbff416fd102cdd32521d30ded",
                "sha256:61b22779b2eebe18d35adea57738ba579a0eeb35e8e60543793af1a05cd4d11e",
                "sha256:28beccf98a2f341d5507dbc255332048bb7b2f5da77281280881e89c15cb29a1",
                "sha256:0088573b023dcfac34146c04a5cb18f90070972c09a260d25daf1919555dba57",
                "sha256:53a4891e2cfc4e6a8ba1285f9d207fca15ee770e7f2dc3668d83c5e7f630b967",
                "sha256:5ce033a6b115db089d8a47e5403b64a903df5ea236d660ff69ea55bda089a44e",
                "sha256:7e336226764c97a914cfc33d2f8f5129668477917e1aa8e7f4d7943a02befdd5",
                "sha256:f5f5669d07001e7e400fd76b2643692e887682695a833708daafc40243663dc4",
                "sha256:944cd74946ca0a3b223ffcdf0ddb8b6f5afe1488a0619f387ed5211fcf42da63",
                "sha256:79078bdc1d93f0d30de82c83fe7ccdbe9a2b9175f6bc18fe216343357fd16092",
                "sha256:0e1e0bf1e7371831e0dc9e32b1a3b762ad6b627c44ba3c4c547cc687d43e9c67",
                "sha256:76712bd4d3dd643a8227af4531aed8c8c425ea527a6a1c8ea2a775e5fc6733cb",
                "sha256:4040831ea2c12db54da5577d0c41a64c44a98e61e4cfc9eb47c27df2e7f4c514",
                "sha256:0053b2e39ca41840516dc3ddbe24a59f71b3102444567406107dd3e6ebe3a87a",
                "sha256:23a055d149b18f6080d65d6d90169d1f636f4dcfef30b6cf61f939d653884fd8",
                "sha256:6c0e0b35b0b6a335ce2ca1362908e4f150c12a688d1ddd5291cfb69b7feef21f",
                "sha256:27e043d9c9226ad6b6d0de87a02655c7d4e92137033a889f5a0aa9d72a1cfd23",
                "sha256:c6c239855185fcb7ac824415a4b3d9b18dd4571c3638ea53471479a42b16c8cf",
                "sha256:ad11a066dfbcb97b46dca7096ea1db2e0fd9290bac65bc645cda852c9b78c06b",
                "sha256:6d512f7f26a702bbd2914dbd02e70d7cbea1f63aa5ba2c5c8cd842484d549a27",
                "sha256:f93bd956435f03f33fe5741ec04d14ae3ebd7938fc6f36073f60e088f30e0402",
                "sha256:4066538d80ac24c37199b2b8c85248408801b16982c899b33d173c6f4c95a7b0",
                "sha256:96831b312a4767e13e6c4732da00e43dc639c03828ca78c9b415ce3fc527d8dc",
                "sha256:1139a2936a67cbafd148f6411fe43db97351beb34122070cb98d65c10d2f52ad",
                "sha256:9881e91ef6568be320f7e53d7261ca58dda0280ef792d57bd6738415465e600a",
                "sha256:04a6b8766533af43ee2c5de458448b7ab0b22544d9c6935b868453770f3ef86d"
            ]
        },
        "Metadata": {
            "LastTagTime": "0001-01-01T00:00:00Z"
        }
    }
]
