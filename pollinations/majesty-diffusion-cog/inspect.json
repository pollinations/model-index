[
    {
        "Id": "sha256:b8cf2e675991cf79cc0b310d49d43276205c353098466cdc7589cc797caaa180",
        "RepoTags": [
            "614871946825.dkr.ecr.us-east-1.amazonaws.com/pollinations/majesty-diffusion-cog:latest"
        ],
        "RepoDigests": [
            "614871946825.dkr.ecr.us-east-1.amazonaws.com/pollinations/majesty-diffusion-cog@sha256:d211cf0eb979ac747c939511d6d72cfe359255e48e1c86f1c0545b01a34f5482"
        ],
        "Parent": "",
        "Comment": "",
        "Created": "2022-08-03T14:04:20.522481512Z",
        "Container": "1d45fe2c794e34b274da982e7299ca393e845ceb6c42bf937df00affdd972aee",
        "ContainerConfig": {
            "Hostname": "1d45fe2c794e",
            "Domainname": "",
            "User": "",
            "AttachStdin": false,
            "AttachStdout": false,
            "AttachStderr": false,
            "ExposedPorts": {
                "5000/tcp": {}
            },
            "Tty": false,
            "OpenStdin": false,
            "StdinOnce": false,
            "Env": [
                "PATH=/root/.pyenv/shims:/root/.pyenv/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin",
                "NVARCH=x86_64",
                "NVIDIA_REQUIRE_CUDA=cuda>=11.2 brand=tesla,driver>=418,driver<419",
                "NV_CUDA_CUDART_VERSION=11.2.152-1",
                "NV_CUDA_COMPAT_PACKAGE=cuda-compat-11-2",
                "CUDA_VERSION=11.2.2",
                "LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/lib/x86_64-linux-gnu:/usr/local/nvidia/lib64:/usr/local/nvidia/bin",
                "NVIDIA_VISIBLE_DEVICES=all",
                "NVIDIA_DRIVER_CAPABILITIES=compute,utility",
                "NV_CUDA_LIB_VERSION=11.2.2-1",
                "NV_NVTX_VERSION=11.2.152-1",
                "NV_LIBNPP_VERSION=11.3.2.152-1",
                "NV_LIBNPP_PACKAGE=libnpp-11-2=11.3.2.152-1",
                "NV_LIBCUSPARSE_VERSION=11.4.1.1152-1",
                "NV_LIBCUBLAS_PACKAGE_NAME=libcublas-11-2",
                "NV_LIBCUBLAS_VERSION=11.4.1.1043-1",
                "NV_LIBCUBLAS_PACKAGE=libcublas-11-2=11.4.1.1043-1",
                "NV_CUDA_CUDART_DEV_VERSION=11.2.152-1",
                "NV_NVML_DEV_VERSION=11.2.152-1",
                "NV_LIBCUSPARSE_DEV_VERSION=11.4.1.1152-1",
                "NV_LIBNPP_DEV_VERSION=11.3.2.152-1",
                "NV_LIBNPP_DEV_PACKAGE=libnpp-dev-11-2=11.3.2.152-1",
                "NV_LIBCUBLAS_DEV_VERSION=11.4.1.1043-1",
                "NV_LIBCUBLAS_DEV_PACKAGE_NAME=libcublas-dev-11-2",
                "NV_LIBCUBLAS_DEV_PACKAGE=libcublas-dev-11-2=11.4.1.1043-1",
                "NV_NVPROF_VERSION=11.2.152-1",
                "NV_NVPROF_DEV_PACKAGE=cuda-nvprof-11-2=11.2.152-1",
                "LIBRARY_PATH=/usr/local/cuda/lib64/stubs",
                "NV_CUDNN_VERSION=8.1.1.33",
                "NV_CUDNN_PACKAGE=libcudnn8=8.1.1.33-1+cuda11.2",
                "NV_CUDNN_PACKAGE_DEV=libcudnn8-dev=8.1.1.33-1+cuda11.2",
                "NV_CUDNN_PACKAGE_NAME=libcudnn8",
                "DEBIAN_FRONTEND=noninteractive",
                "PYTHONUNBUFFERED=1"
            ],
            "Cmd": [
                "/bin/sh",
                "-c",
                "#(nop) ",
                "LABEL run.cog.version=0.4.0"
            ],
            "ArgsEscaped": true,
            "Image": "sha256:39fdf15600ea27b12d5b04b74a23e59052543b0ea2b542d817b72d2c333286bb",
            "Volumes": null,
            "WorkingDir": "/src",
            "Entrypoint": null,
            "OnBuild": null,
            "Labels": {
                "com.nvidia.cudnn.version": "8.1.1.33",
                "maintainer": "NVIDIA CORPORATION <cudatools@nvidia.com>",
                "org.cogmodel.cog_version": "0.4.0",
                "org.cogmodel.config": "{\"build\":{\"gpu\":true,\"python_version\":\"3.7\",\"python_packages\":[\"numpy==1.21.6\",\"torch==1.11.0\",\"torchvision==0.12.0\",\"omegaconf==2.2.2\",\"pytorch-lightning==1.6.4\",\"torch-fidelity==0.3.0\",\"einops==0.4.1\",\"transformers==4.19.2\",\"open_clip_torch==1.2.1\",\"autokeras==1.0.19\"],\"run\":[\"mkdir -p /content/models/\",\"git clone https://github.com/multimodalart/latent-diffusion --branch 1.6\",\"git clone https://github.com/CompVis/taming-transformers\",\"git clone https://github.com/TencentARC/GFPGAN\",\"curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | bash\",\"apt-get install git-lfs\",\"git lfs install\",\"git lfs clone https://huggingface.co/datasets/multimodalart/latent-majesty-diffusion-settings\",\"git lfs clone https://github.com/LAION-AI/aesthetic-predictor\",\"pip install -e ./taming-transformers\",\"pip install omegaconf\\u003e=2.0.0 pytorch-lightning\\u003e=1.0.8 torch-fidelity einops\",\"pip install transformers\",\"pip install dotmap\",\"pip install resize-right\",\"pip install piq\",\"pip install lpips\",\"pip install basicsr\",\"pip install facexlib\",\"pip install realesrgan\",\"git clone https://github.com/apolinario/Multi-Modal-Comparators --branch gradient_checkpointing\",\"pip install poetry\",\"cd Multi-Modal-Comparators; poetry build; cd ..\",\"cd Multi-Modal-Comparators; pip install dist/mmc*.whl; cd ..\",\"python Multi-Modal-Comparators/src/mmc/napm_installs/__init__.py\",\"wget -O /content/models/latent_diffusion_txt2img_f8_large.ckpt https://ommer-lab.com/files/latent-diffusion/nitro/txt2img-f8-large/model.ckpt --no-check-certificate\",\"wget -O /content/models/txt2img-f8-large-jack000-finetuned-fp16.ckpt https://huggingface.co/multimodalart/compvis-latent-diffusion-text2img-large/resolve/main/txt2img-f8-large-jack000-finetuned-fp16.ckpt --no-check-certificate\",\"wget -O /content/models/ongo.pt https://huggingface.co/laion/ongo/resolve/main/ongo.pt\",\"wget -O /content/models/erlich.pt https://huggingface.co/laion/erlich/resolve/main/model/ema_0.9999_120000.pt\",\"wget -O /content/models/ava_vit_l_14_336_linear.pth https://models.nmb.ai/majesty/ava_vit_l_14_336_linear.pth\",\"wget -O /content/models/sa_0_4_vit_l_14_linear.pth https://models.nmb.ai/majesty/sa_0_4_vit_l_14_linear.pth\",\"wget -O /content/models/ava_vit_l_14_linear.pth https://models.nmb.ai/majesty/ava_vit_l_14_linear.pth\",\"wget -O /content/models/ava_vit_b_16_linear.pth https://the-eye.eu/public/AI/models/v-diffusion/ava_vit_b_16_linear.pth\",\"wget -O /content/models/sa_0_4_vit_b_16_linear.pth https://models.nmb.ai/majesty/sa_0_4_vit_b_16_linear.pth\",\"wget -O /content/models/sa_0_4_vit_b_32_linear.pth https://models.nmb.ai/majesty/sa_0_4_vit_b_32_linear.pth\",\"wget -O /content/models/openimages_512x_png_embed224.npz https://github.com/nshepperd/jax-guided-diffusion/raw/8437b4d390fcc6b57b89cedcbaf1629993c09d03/data/openimages_512x_png_embed224.npz\",\"wget -O /content/models/imagenet_512x_jpg_embed224.npz https://github.com/nshepperd/jax-guided-diffusion/raw/8437b4d390fcc6b57b89cedcbaf1629993c09d03/data/imagenet_512x_jpg_embed224.npz\",\"wget -O /content/models/GFPGANv1.3.pth https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.3.pth\",\"cp /content/models/GFPGANv1.3.pth GFPGAN/experiments/pretrained_models/GFPGANv1.3.pth\"],\"system_packages\":[\"aria2\",\"ffmpeg\"],\"cuda\":\"11.2.2\",\"cudnn\":\"8\"},\"predict\":\"predict.py:Predictor\"}",
                "org.cogmodel.deprecated": "The org.cogmodel labels are deprecated. Use run.cog.",
                "org.cogmodel.openapi_schema": "{\"components\":{\"schemas\":{\"HTTPValidationError\":{\"properties\":{\"detail\":{\"items\":{\"$ref\":\"#/components/schemas/ValidationError\"},\"title\":\"Detail\",\"type\":\"array\"}},\"title\":\"HTTPValidationError\",\"type\":\"object\"},\"Input\":{\"properties\":{\"Prompt\":{\"default\":\"\",\"description\":\"Your text prompt.\",\"title\":\"Prompt\",\"type\":\"string\",\"x-order\":0},\"latent_diffusion_guidance_scale\":{\"default\":12,\"description\":\"Balance between creativity and coherent composition. Try values between 0-15. Lower values help with text interpretation and creativity, higher help with composition. \",\"title\":\"Latent Diffusion Guidance Scale\",\"type\":\"integer\",\"x-order\":2},\"latent_diffusion_model\":{\"allOf\":[{\"$ref\":\"#/components/schemas/latent_diffusion_model\"}],\"default\":\"finetuned\",\"description\":\"Original is the previous LAION model. Finetuned should be better but cannot do text. One of:  [\\\"original\\\", \\\"finetuned\\\", \\\"ongo (fine tuned in paintings)\\\", \\\"erlich (fine tuned in logos)\\\"]\",\"x-order\":1}},\"title\":\"Input\",\"type\":\"object\"},\"Output\":{\"title\":\"Output\",\"type\":\"null\"},\"Request\":{\"description\":\"The request body for a prediction\",\"properties\":{\"input\":{\"$ref\":\"#/components/schemas/Input\"},\"output_file_prefix\":{\"title\":\"Output File Prefix\",\"type\":\"string\"}},\"title\":\"Request\",\"type\":\"object\"},\"Response\":{\"description\":\"The response body for a prediction\",\"properties\":{\"error\":{\"title\":\"Error\",\"type\":\"string\"},\"output\":{\"$ref\":\"#/components/schemas/Output\"},\"status\":{\"$ref\":\"#/components/schemas/Status\"}},\"required\":[\"status\"],\"title\":\"Response\",\"type\":\"object\"},\"Status\":{\"description\":\"An enumeration.\",\"enum\":[\"processing\",\"succeeded\",\"failed\"],\"title\":\"Status\",\"type\":\"string\"},\"ValidationError\":{\"properties\":{\"loc\":{\"items\":{\"anyOf\":[{\"type\":\"string\"},{\"type\":\"integer\"}]},\"title\":\"Location\",\"type\":\"array\"},\"msg\":{\"title\":\"Message\",\"type\":\"string\"},\"type\":{\"title\":\"Error Type\",\"type\":\"string\"}},\"required\":[\"loc\",\"msg\",\"type\"],\"title\":\"ValidationError\",\"type\":\"object\"},\"latent_diffusion_model\":{\"description\":\"An enumeration.\",\"enum\":[\"original\",\"finetuned\",\"ongo (fine tuned in paintings)\",\"erlich (fine tuned in logos)\"],\"title\":\"latent_diffusion_model\",\"type\":\"string\"}}},\"info\":{\"title\":\"Cog\",\"version\":\"0.1.0\"},\"openapi\":\"3.0.2\",\"paths\":{\"/\":{\"get\":{\"operationId\":\"root__get\",\"responses\":{\"200\":{\"content\":{\"application/json\":{\"schema\":{}}},\"description\":\"Successful Response\"}},\"summary\":\"Root\"}},\"/predictions\":{\"post\":{\"description\":\"Run a single prediction on the model\",\"operationId\":\"predict_predictions_post\",\"requestBody\":{\"content\":{\"application/json\":{\"schema\":{\"$ref\":\"#/components/schemas/Request\"}}}},\"responses\":{\"200\":{\"content\":{\"application/json\":{\"schema\":{\"$ref\":\"#/components/schemas/Response\"}}},\"description\":\"Successful Response\"},\"422\":{\"content\":{\"application/json\":{\"schema\":{\"$ref\":\"#/components/schemas/HTTPValidationError\"}}},\"description\":\"Validation Error\"}},\"summary\":\"Predict\"}}}}",
                "run.cog.config": "{\"build\":{\"gpu\":true,\"python_version\":\"3.7\",\"python_packages\":[\"numpy==1.21.6\",\"torch==1.11.0\",\"torchvision==0.12.0\",\"omegaconf==2.2.2\",\"pytorch-lightning==1.6.4\",\"torch-fidelity==0.3.0\",\"einops==0.4.1\",\"transformers==4.19.2\",\"open_clip_torch==1.2.1\",\"autokeras==1.0.19\"],\"run\":[\"mkdir -p /content/models/\",\"git clone https://github.com/multimodalart/latent-diffusion --branch 1.6\",\"git clone https://github.com/CompVis/taming-transformers\",\"git clone https://github.com/TencentARC/GFPGAN\",\"curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | bash\",\"apt-get install git-lfs\",\"git lfs install\",\"git lfs clone https://huggingface.co/datasets/multimodalart/latent-majesty-diffusion-settings\",\"git lfs clone https://github.com/LAION-AI/aesthetic-predictor\",\"pip install -e ./taming-transformers\",\"pip install omegaconf\\u003e=2.0.0 pytorch-lightning\\u003e=1.0.8 torch-fidelity einops\",\"pip install transformers\",\"pip install dotmap\",\"pip install resize-right\",\"pip install piq\",\"pip install lpips\",\"pip install basicsr\",\"pip install facexlib\",\"pip install realesrgan\",\"git clone https://github.com/apolinario/Multi-Modal-Comparators --branch gradient_checkpointing\",\"pip install poetry\",\"cd Multi-Modal-Comparators; poetry build; cd ..\",\"cd Multi-Modal-Comparators; pip install dist/mmc*.whl; cd ..\",\"python Multi-Modal-Comparators/src/mmc/napm_installs/__init__.py\",\"wget -O /content/models/latent_diffusion_txt2img_f8_large.ckpt https://ommer-lab.com/files/latent-diffusion/nitro/txt2img-f8-large/model.ckpt --no-check-certificate\",\"wget -O /content/models/txt2img-f8-large-jack000-finetuned-fp16.ckpt https://huggingface.co/multimodalart/compvis-latent-diffusion-text2img-large/resolve/main/txt2img-f8-large-jack000-finetuned-fp16.ckpt --no-check-certificate\",\"wget -O /content/models/ongo.pt https://huggingface.co/laion/ongo/resolve/main/ongo.pt\",\"wget -O /content/models/erlich.pt https://huggingface.co/laion/erlich/resolve/main/model/ema_0.9999_120000.pt\",\"wget -O /content/models/ava_vit_l_14_336_linear.pth https://models.nmb.ai/majesty/ava_vit_l_14_336_linear.pth\",\"wget -O /content/models/sa_0_4_vit_l_14_linear.pth https://models.nmb.ai/majesty/sa_0_4_vit_l_14_linear.pth\",\"wget -O /content/models/ava_vit_l_14_linear.pth https://models.nmb.ai/majesty/ava_vit_l_14_linear.pth\",\"wget -O /content/models/ava_vit_b_16_linear.pth https://the-eye.eu/public/AI/models/v-diffusion/ava_vit_b_16_linear.pth\",\"wget -O /content/models/sa_0_4_vit_b_16_linear.pth https://models.nmb.ai/majesty/sa_0_4_vit_b_16_linear.pth\",\"wget -O /content/models/sa_0_4_vit_b_32_linear.pth https://models.nmb.ai/majesty/sa_0_4_vit_b_32_linear.pth\",\"wget -O /content/models/openimages_512x_png_embed224.npz https://github.com/nshepperd/jax-guided-diffusion/raw/8437b4d390fcc6b57b89cedcbaf1629993c09d03/data/openimages_512x_png_embed224.npz\",\"wget -O /content/models/imagenet_512x_jpg_embed224.npz https://github.com/nshepperd/jax-guided-diffusion/raw/8437b4d390fcc6b57b89cedcbaf1629993c09d03/data/imagenet_512x_jpg_embed224.npz\",\"wget -O /content/models/GFPGANv1.3.pth https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.3.pth\",\"cp /content/models/GFPGANv1.3.pth GFPGAN/experiments/pretrained_models/GFPGANv1.3.pth\"],\"system_packages\":[\"aria2\",\"ffmpeg\"],\"cuda\":\"11.2.2\",\"cudnn\":\"8\"},\"predict\":\"predict.py:Predictor\"}",
                "run.cog.openapi_schema": "{\"components\":{\"schemas\":{\"HTTPValidationError\":{\"properties\":{\"detail\":{\"items\":{\"$ref\":\"#/components/schemas/ValidationError\"},\"title\":\"Detail\",\"type\":\"array\"}},\"title\":\"HTTPValidationError\",\"type\":\"object\"},\"Input\":{\"properties\":{\"Prompt\":{\"default\":\"\",\"description\":\"Your text prompt.\",\"title\":\"Prompt\",\"type\":\"string\",\"x-order\":0},\"latent_diffusion_guidance_scale\":{\"default\":12,\"description\":\"Balance between creativity and coherent composition. Try values between 0-15. Lower values help with text interpretation and creativity, higher help with composition. \",\"title\":\"Latent Diffusion Guidance Scale\",\"type\":\"integer\",\"x-order\":2},\"latent_diffusion_model\":{\"allOf\":[{\"$ref\":\"#/components/schemas/latent_diffusion_model\"}],\"default\":\"finetuned\",\"description\":\"Original is the previous LAION model. Finetuned should be better but cannot do text. One of:  [\\\"original\\\", \\\"finetuned\\\", \\\"ongo (fine tuned in paintings)\\\", \\\"erlich (fine tuned in logos)\\\"]\",\"x-order\":1}},\"title\":\"Input\",\"type\":\"object\"},\"Output\":{\"title\":\"Output\",\"type\":\"null\"},\"Request\":{\"description\":\"The request body for a prediction\",\"properties\":{\"input\":{\"$ref\":\"#/components/schemas/Input\"},\"output_file_prefix\":{\"title\":\"Output File Prefix\",\"type\":\"string\"}},\"title\":\"Request\",\"type\":\"object\"},\"Response\":{\"description\":\"The response body for a prediction\",\"properties\":{\"error\":{\"title\":\"Error\",\"type\":\"string\"},\"output\":{\"$ref\":\"#/components/schemas/Output\"},\"status\":{\"$ref\":\"#/components/schemas/Status\"}},\"required\":[\"status\"],\"title\":\"Response\",\"type\":\"object\"},\"Status\":{\"description\":\"An enumeration.\",\"enum\":[\"processing\",\"succeeded\",\"failed\"],\"title\":\"Status\",\"type\":\"string\"},\"ValidationError\":{\"properties\":{\"loc\":{\"items\":{\"anyOf\":[{\"type\":\"string\"},{\"type\":\"integer\"}]},\"title\":\"Location\",\"type\":\"array\"},\"msg\":{\"title\":\"Message\",\"type\":\"string\"},\"type\":{\"title\":\"Error Type\",\"type\":\"string\"}},\"required\":[\"loc\",\"msg\",\"type\"],\"title\":\"ValidationError\",\"type\":\"object\"},\"latent_diffusion_model\":{\"description\":\"An enumeration.\",\"enum\":[\"original\",\"finetuned\",\"ongo (fine tuned in paintings)\",\"erlich (fine tuned in logos)\"],\"title\":\"latent_diffusion_model\",\"type\":\"string\"}}},\"info\":{\"title\":\"Cog\",\"version\":\"0.1.0\"},\"openapi\":\"3.0.2\",\"paths\":{\"/\":{\"get\":{\"operationId\":\"root__get\",\"responses\":{\"200\":{\"content\":{\"application/json\":{\"schema\":{}}},\"description\":\"Successful Response\"}},\"summary\":\"Root\"}},\"/predictions\":{\"post\":{\"description\":\"Run a single prediction on the model\",\"operationId\":\"predict_predictions_post\",\"requestBody\":{\"content\":{\"application/json\":{\"schema\":{\"$ref\":\"#/components/schemas/Request\"}}}},\"responses\":{\"200\":{\"content\":{\"application/json\":{\"schema\":{\"$ref\":\"#/components/schemas/Response\"}}},\"description\":\"Successful Response\"},\"422\":{\"content\":{\"application/json\":{\"schema\":{\"$ref\":\"#/components/schemas/HTTPValidationError\"}}},\"description\":\"Validation Error\"}},\"summary\":\"Predict\"}}}}",
                "run.cog.version": "0.4.0"
            }
        },
        "DockerVersion": "20.10.17+azure-1",
        "Author": "",
        "Config": {
            "Hostname": "",
            "Domainname": "",
            "User": "",
            "AttachStdin": false,
            "AttachStdout": false,
            "AttachStderr": false,
            "ExposedPorts": {
                "5000/tcp": {}
            },
            "Tty": false,
            "OpenStdin": false,
            "StdinOnce": false,
            "Env": [
                "PATH=/root/.pyenv/shims:/root/.pyenv/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin",
                "NVARCH=x86_64",
                "NVIDIA_REQUIRE_CUDA=cuda>=11.2 brand=tesla,driver>=418,driver<419",
                "NV_CUDA_CUDART_VERSION=11.2.152-1",
                "NV_CUDA_COMPAT_PACKAGE=cuda-compat-11-2",
                "CUDA_VERSION=11.2.2",
                "LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/lib/x86_64-linux-gnu:/usr/local/nvidia/lib64:/usr/local/nvidia/bin",
                "NVIDIA_VISIBLE_DEVICES=all",
                "NVIDIA_DRIVER_CAPABILITIES=compute,utility",
                "NV_CUDA_LIB_VERSION=11.2.2-1",
                "NV_NVTX_VERSION=11.2.152-1",
                "NV_LIBNPP_VERSION=11.3.2.152-1",
                "NV_LIBNPP_PACKAGE=libnpp-11-2=11.3.2.152-1",
                "NV_LIBCUSPARSE_VERSION=11.4.1.1152-1",
                "NV_LIBCUBLAS_PACKAGE_NAME=libcublas-11-2",
                "NV_LIBCUBLAS_VERSION=11.4.1.1043-1",
                "NV_LIBCUBLAS_PACKAGE=libcublas-11-2=11.4.1.1043-1",
                "NV_CUDA_CUDART_DEV_VERSION=11.2.152-1",
                "NV_NVML_DEV_VERSION=11.2.152-1",
                "NV_LIBCUSPARSE_DEV_VERSION=11.4.1.1152-1",
                "NV_LIBNPP_DEV_VERSION=11.3.2.152-1",
                "NV_LIBNPP_DEV_PACKAGE=libnpp-dev-11-2=11.3.2.152-1",
                "NV_LIBCUBLAS_DEV_VERSION=11.4.1.1043-1",
                "NV_LIBCUBLAS_DEV_PACKAGE_NAME=libcublas-dev-11-2",
                "NV_LIBCUBLAS_DEV_PACKAGE=libcublas-dev-11-2=11.4.1.1043-1",
                "NV_NVPROF_VERSION=11.2.152-1",
                "NV_NVPROF_DEV_PACKAGE=cuda-nvprof-11-2=11.2.152-1",
                "LIBRARY_PATH=/usr/local/cuda/lib64/stubs",
                "NV_CUDNN_VERSION=8.1.1.33",
                "NV_CUDNN_PACKAGE=libcudnn8=8.1.1.33-1+cuda11.2",
                "NV_CUDNN_PACKAGE_DEV=libcudnn8-dev=8.1.1.33-1+cuda11.2",
                "NV_CUDNN_PACKAGE_NAME=libcudnn8",
                "DEBIAN_FRONTEND=noninteractive",
                "PYTHONUNBUFFERED=1"
            ],
            "Cmd": [
                "python",
                "-m",
                "cog.server.http"
            ],
            "ArgsEscaped": true,
            "Image": "sha256:39fdf15600ea27b12d5b04b74a23e59052543b0ea2b542d817b72d2c333286bb",
            "Volumes": null,
            "WorkingDir": "/src",
            "Entrypoint": null,
            "OnBuild": null,
            "Labels": {
                "com.nvidia.cudnn.version": "8.1.1.33",
                "maintainer": "NVIDIA CORPORATION <cudatools@nvidia.com>",
                "org.cogmodel.cog_version": "0.4.0",
                "org.cogmodel.config": "{\"build\":{\"gpu\":true,\"python_version\":\"3.7\",\"python_packages\":[\"numpy==1.21.6\",\"torch==1.11.0\",\"torchvision==0.12.0\",\"omegaconf==2.2.2\",\"pytorch-lightning==1.6.4\",\"torch-fidelity==0.3.0\",\"einops==0.4.1\",\"transformers==4.19.2\",\"open_clip_torch==1.2.1\",\"autokeras==1.0.19\"],\"run\":[\"mkdir -p /content/models/\",\"git clone https://github.com/multimodalart/latent-diffusion --branch 1.6\",\"git clone https://github.com/CompVis/taming-transformers\",\"git clone https://github.com/TencentARC/GFPGAN\",\"curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | bash\",\"apt-get install git-lfs\",\"git lfs install\",\"git lfs clone https://huggingface.co/datasets/multimodalart/latent-majesty-diffusion-settings\",\"git lfs clone https://github.com/LAION-AI/aesthetic-predictor\",\"pip install -e ./taming-transformers\",\"pip install omegaconf\\u003e=2.0.0 pytorch-lightning\\u003e=1.0.8 torch-fidelity einops\",\"pip install transformers\",\"pip install dotmap\",\"pip install resize-right\",\"pip install piq\",\"pip install lpips\",\"pip install basicsr\",\"pip install facexlib\",\"pip install realesrgan\",\"git clone https://github.com/apolinario/Multi-Modal-Comparators --branch gradient_checkpointing\",\"pip install poetry\",\"cd Multi-Modal-Comparators; poetry build; cd ..\",\"cd Multi-Modal-Comparators; pip install dist/mmc*.whl; cd ..\",\"python Multi-Modal-Comparators/src/mmc/napm_installs/__init__.py\",\"wget -O /content/models/latent_diffusion_txt2img_f8_large.ckpt https://ommer-lab.com/files/latent-diffusion/nitro/txt2img-f8-large/model.ckpt --no-check-certificate\",\"wget -O /content/models/txt2img-f8-large-jack000-finetuned-fp16.ckpt https://huggingface.co/multimodalart/compvis-latent-diffusion-text2img-large/resolve/main/txt2img-f8-large-jack000-finetuned-fp16.ckpt --no-check-certificate\",\"wget -O /content/models/ongo.pt https://huggingface.co/laion/ongo/resolve/main/ongo.pt\",\"wget -O /content/models/erlich.pt https://huggingface.co/laion/erlich/resolve/main/model/ema_0.9999_120000.pt\",\"wget -O /content/models/ava_vit_l_14_336_linear.pth https://models.nmb.ai/majesty/ava_vit_l_14_336_linear.pth\",\"wget -O /content/models/sa_0_4_vit_l_14_linear.pth https://models.nmb.ai/majesty/sa_0_4_vit_l_14_linear.pth\",\"wget -O /content/models/ava_vit_l_14_linear.pth https://models.nmb.ai/majesty/ava_vit_l_14_linear.pth\",\"wget -O /content/models/ava_vit_b_16_linear.pth https://the-eye.eu/public/AI/models/v-diffusion/ava_vit_b_16_linear.pth\",\"wget -O /content/models/sa_0_4_vit_b_16_linear.pth https://models.nmb.ai/majesty/sa_0_4_vit_b_16_linear.pth\",\"wget -O /content/models/sa_0_4_vit_b_32_linear.pth https://models.nmb.ai/majesty/sa_0_4_vit_b_32_linear.pth\",\"wget -O /content/models/openimages_512x_png_embed224.npz https://github.com/nshepperd/jax-guided-diffusion/raw/8437b4d390fcc6b57b89cedcbaf1629993c09d03/data/openimages_512x_png_embed224.npz\",\"wget -O /content/models/imagenet_512x_jpg_embed224.npz https://github.com/nshepperd/jax-guided-diffusion/raw/8437b4d390fcc6b57b89cedcbaf1629993c09d03/data/imagenet_512x_jpg_embed224.npz\",\"wget -O /content/models/GFPGANv1.3.pth https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.3.pth\",\"cp /content/models/GFPGANv1.3.pth GFPGAN/experiments/pretrained_models/GFPGANv1.3.pth\"],\"system_packages\":[\"aria2\",\"ffmpeg\"],\"cuda\":\"11.2.2\",\"cudnn\":\"8\"},\"predict\":\"predict.py:Predictor\"}",
                "org.cogmodel.deprecated": "The org.cogmodel labels are deprecated. Use run.cog.",
                "org.cogmodel.openapi_schema": "{\"components\":{\"schemas\":{\"HTTPValidationError\":{\"properties\":{\"detail\":{\"items\":{\"$ref\":\"#/components/schemas/ValidationError\"},\"title\":\"Detail\",\"type\":\"array\"}},\"title\":\"HTTPValidationError\",\"type\":\"object\"},\"Input\":{\"properties\":{\"Prompt\":{\"default\":\"\",\"description\":\"Your text prompt.\",\"title\":\"Prompt\",\"type\":\"string\",\"x-order\":0},\"latent_diffusion_guidance_scale\":{\"default\":12,\"description\":\"Balance between creativity and coherent composition. Try values between 0-15. Lower values help with text interpretation and creativity, higher help with composition. \",\"title\":\"Latent Diffusion Guidance Scale\",\"type\":\"integer\",\"x-order\":2},\"latent_diffusion_model\":{\"allOf\":[{\"$ref\":\"#/components/schemas/latent_diffusion_model\"}],\"default\":\"finetuned\",\"description\":\"Original is the previous LAION model. Finetuned should be better but cannot do text. One of:  [\\\"original\\\", \\\"finetuned\\\", \\\"ongo (fine tuned in paintings)\\\", \\\"erlich (fine tuned in logos)\\\"]\",\"x-order\":1}},\"title\":\"Input\",\"type\":\"object\"},\"Output\":{\"title\":\"Output\",\"type\":\"null\"},\"Request\":{\"description\":\"The request body for a prediction\",\"properties\":{\"input\":{\"$ref\":\"#/components/schemas/Input\"},\"output_file_prefix\":{\"title\":\"Output File Prefix\",\"type\":\"string\"}},\"title\":\"Request\",\"type\":\"object\"},\"Response\":{\"description\":\"The response body for a prediction\",\"properties\":{\"error\":{\"title\":\"Error\",\"type\":\"string\"},\"output\":{\"$ref\":\"#/components/schemas/Output\"},\"status\":{\"$ref\":\"#/components/schemas/Status\"}},\"required\":[\"status\"],\"title\":\"Response\",\"type\":\"object\"},\"Status\":{\"description\":\"An enumeration.\",\"enum\":[\"processing\",\"succeeded\",\"failed\"],\"title\":\"Status\",\"type\":\"string\"},\"ValidationError\":{\"properties\":{\"loc\":{\"items\":{\"anyOf\":[{\"type\":\"string\"},{\"type\":\"integer\"}]},\"title\":\"Location\",\"type\":\"array\"},\"msg\":{\"title\":\"Message\",\"type\":\"string\"},\"type\":{\"title\":\"Error Type\",\"type\":\"string\"}},\"required\":[\"loc\",\"msg\",\"type\"],\"title\":\"ValidationError\",\"type\":\"object\"},\"latent_diffusion_model\":{\"description\":\"An enumeration.\",\"enum\":[\"original\",\"finetuned\",\"ongo (fine tuned in paintings)\",\"erlich (fine tuned in logos)\"],\"title\":\"latent_diffusion_model\",\"type\":\"string\"}}},\"info\":{\"title\":\"Cog\",\"version\":\"0.1.0\"},\"openapi\":\"3.0.2\",\"paths\":{\"/\":{\"get\":{\"operationId\":\"root__get\",\"responses\":{\"200\":{\"content\":{\"application/json\":{\"schema\":{}}},\"description\":\"Successful Response\"}},\"summary\":\"Root\"}},\"/predictions\":{\"post\":{\"description\":\"Run a single prediction on the model\",\"operationId\":\"predict_predictions_post\",\"requestBody\":{\"content\":{\"application/json\":{\"schema\":{\"$ref\":\"#/components/schemas/Request\"}}}},\"responses\":{\"200\":{\"content\":{\"application/json\":{\"schema\":{\"$ref\":\"#/components/schemas/Response\"}}},\"description\":\"Successful Response\"},\"422\":{\"content\":{\"application/json\":{\"schema\":{\"$ref\":\"#/components/schemas/HTTPValidationError\"}}},\"description\":\"Validation Error\"}},\"summary\":\"Predict\"}}}}",
                "run.cog.config": "{\"build\":{\"gpu\":true,\"python_version\":\"3.7\",\"python_packages\":[\"numpy==1.21.6\",\"torch==1.11.0\",\"torchvision==0.12.0\",\"omegaconf==2.2.2\",\"pytorch-lightning==1.6.4\",\"torch-fidelity==0.3.0\",\"einops==0.4.1\",\"transformers==4.19.2\",\"open_clip_torch==1.2.1\",\"autokeras==1.0.19\"],\"run\":[\"mkdir -p /content/models/\",\"git clone https://github.com/multimodalart/latent-diffusion --branch 1.6\",\"git clone https://github.com/CompVis/taming-transformers\",\"git clone https://github.com/TencentARC/GFPGAN\",\"curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | bash\",\"apt-get install git-lfs\",\"git lfs install\",\"git lfs clone https://huggingface.co/datasets/multimodalart/latent-majesty-diffusion-settings\",\"git lfs clone https://github.com/LAION-AI/aesthetic-predictor\",\"pip install -e ./taming-transformers\",\"pip install omegaconf\\u003e=2.0.0 pytorch-lightning\\u003e=1.0.8 torch-fidelity einops\",\"pip install transformers\",\"pip install dotmap\",\"pip install resize-right\",\"pip install piq\",\"pip install lpips\",\"pip install basicsr\",\"pip install facexlib\",\"pip install realesrgan\",\"git clone https://github.com/apolinario/Multi-Modal-Comparators --branch gradient_checkpointing\",\"pip install poetry\",\"cd Multi-Modal-Comparators; poetry build; cd ..\",\"cd Multi-Modal-Comparators; pip install dist/mmc*.whl; cd ..\",\"python Multi-Modal-Comparators/src/mmc/napm_installs/__init__.py\",\"wget -O /content/models/latent_diffusion_txt2img_f8_large.ckpt https://ommer-lab.com/files/latent-diffusion/nitro/txt2img-f8-large/model.ckpt --no-check-certificate\",\"wget -O /content/models/txt2img-f8-large-jack000-finetuned-fp16.ckpt https://huggingface.co/multimodalart/compvis-latent-diffusion-text2img-large/resolve/main/txt2img-f8-large-jack000-finetuned-fp16.ckpt --no-check-certificate\",\"wget -O /content/models/ongo.pt https://huggingface.co/laion/ongo/resolve/main/ongo.pt\",\"wget -O /content/models/erlich.pt https://huggingface.co/laion/erlich/resolve/main/model/ema_0.9999_120000.pt\",\"wget -O /content/models/ava_vit_l_14_336_linear.pth https://models.nmb.ai/majesty/ava_vit_l_14_336_linear.pth\",\"wget -O /content/models/sa_0_4_vit_l_14_linear.pth https://models.nmb.ai/majesty/sa_0_4_vit_l_14_linear.pth\",\"wget -O /content/models/ava_vit_l_14_linear.pth https://models.nmb.ai/majesty/ava_vit_l_14_linear.pth\",\"wget -O /content/models/ava_vit_b_16_linear.pth https://the-eye.eu/public/AI/models/v-diffusion/ava_vit_b_16_linear.pth\",\"wget -O /content/models/sa_0_4_vit_b_16_linear.pth https://models.nmb.ai/majesty/sa_0_4_vit_b_16_linear.pth\",\"wget -O /content/models/sa_0_4_vit_b_32_linear.pth https://models.nmb.ai/majesty/sa_0_4_vit_b_32_linear.pth\",\"wget -O /content/models/openimages_512x_png_embed224.npz https://github.com/nshepperd/jax-guided-diffusion/raw/8437b4d390fcc6b57b89cedcbaf1629993c09d03/data/openimages_512x_png_embed224.npz\",\"wget -O /content/models/imagenet_512x_jpg_embed224.npz https://github.com/nshepperd/jax-guided-diffusion/raw/8437b4d390fcc6b57b89cedcbaf1629993c09d03/data/imagenet_512x_jpg_embed224.npz\",\"wget -O /content/models/GFPGANv1.3.pth https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.3.pth\",\"cp /content/models/GFPGANv1.3.pth GFPGAN/experiments/pretrained_models/GFPGANv1.3.pth\"],\"system_packages\":[\"aria2\",\"ffmpeg\"],\"cuda\":\"11.2.2\",\"cudnn\":\"8\"},\"predict\":\"predict.py:Predictor\"}",
                "run.cog.openapi_schema": "{\"components\":{\"schemas\":{\"HTTPValidationError\":{\"properties\":{\"detail\":{\"items\":{\"$ref\":\"#/components/schemas/ValidationError\"},\"title\":\"Detail\",\"type\":\"array\"}},\"title\":\"HTTPValidationError\",\"type\":\"object\"},\"Input\":{\"properties\":{\"Prompt\":{\"default\":\"\",\"description\":\"Your text prompt.\",\"title\":\"Prompt\",\"type\":\"string\",\"x-order\":0},\"latent_diffusion_guidance_scale\":{\"default\":12,\"description\":\"Balance between creativity and coherent composition. Try values between 0-15. Lower values help with text interpretation and creativity, higher help with composition. \",\"title\":\"Latent Diffusion Guidance Scale\",\"type\":\"integer\",\"x-order\":2},\"latent_diffusion_model\":{\"allOf\":[{\"$ref\":\"#/components/schemas/latent_diffusion_model\"}],\"default\":\"finetuned\",\"description\":\"Original is the previous LAION model. Finetuned should be better but cannot do text. One of:  [\\\"original\\\", \\\"finetuned\\\", \\\"ongo (fine tuned in paintings)\\\", \\\"erlich (fine tuned in logos)\\\"]\",\"x-order\":1}},\"title\":\"Input\",\"type\":\"object\"},\"Output\":{\"title\":\"Output\",\"type\":\"null\"},\"Request\":{\"description\":\"The request body for a prediction\",\"properties\":{\"input\":{\"$ref\":\"#/components/schemas/Input\"},\"output_file_prefix\":{\"title\":\"Output File Prefix\",\"type\":\"string\"}},\"title\":\"Request\",\"type\":\"object\"},\"Response\":{\"description\":\"The response body for a prediction\",\"properties\":{\"error\":{\"title\":\"Error\",\"type\":\"string\"},\"output\":{\"$ref\":\"#/components/schemas/Output\"},\"status\":{\"$ref\":\"#/components/schemas/Status\"}},\"required\":[\"status\"],\"title\":\"Response\",\"type\":\"object\"},\"Status\":{\"description\":\"An enumeration.\",\"enum\":[\"processing\",\"succeeded\",\"failed\"],\"title\":\"Status\",\"type\":\"string\"},\"ValidationError\":{\"properties\":{\"loc\":{\"items\":{\"anyOf\":[{\"type\":\"string\"},{\"type\":\"integer\"}]},\"title\":\"Location\",\"type\":\"array\"},\"msg\":{\"title\":\"Message\",\"type\":\"string\"},\"type\":{\"title\":\"Error Type\",\"type\":\"string\"}},\"required\":[\"loc\",\"msg\",\"type\"],\"title\":\"ValidationError\",\"type\":\"object\"},\"latent_diffusion_model\":{\"description\":\"An enumeration.\",\"enum\":[\"original\",\"finetuned\",\"ongo (fine tuned in paintings)\",\"erlich (fine tuned in logos)\"],\"title\":\"latent_diffusion_model\",\"type\":\"string\"}}},\"info\":{\"title\":\"Cog\",\"version\":\"0.1.0\"},\"openapi\":\"3.0.2\",\"paths\":{\"/\":{\"get\":{\"operationId\":\"root__get\",\"responses\":{\"200\":{\"content\":{\"application/json\":{\"schema\":{}}},\"description\":\"Successful Response\"}},\"summary\":\"Root\"}},\"/predictions\":{\"post\":{\"description\":\"Run a single prediction on the model\",\"operationId\":\"predict_predictions_post\",\"requestBody\":{\"content\":{\"application/json\":{\"schema\":{\"$ref\":\"#/components/schemas/Request\"}}}},\"responses\":{\"200\":{\"content\":{\"application/json\":{\"schema\":{\"$ref\":\"#/components/schemas/Response\"}}},\"description\":\"Successful Response\"},\"422\":{\"content\":{\"application/json\":{\"schema\":{\"$ref\":\"#/components/schemas/HTTPValidationError\"}}},\"description\":\"Validation Error\"}},\"summary\":\"Predict\"}}}}",
                "run.cog.version": "0.4.0"
            }
        },
        "Architecture": "amd64",
        "Os": "linux",
        "Size": 29391487279,
        "VirtualSize": 29391487279,
        "GraphDriver": {
            "Data": {
                "LowerDir": "/var/lib/docker/overlay2/6914e51c58681f53bc48733a44f9e749744762a4f254cdb45cd1d2a83383ba58/diff:/var/lib/docker/overlay2/701d282984f0877afb5f75f4ebaef208db433d41bb866ba0be64cb5856c294f1/diff:/var/lib/docker/overlay2/54d1fe439233d1e347d191995258e2a4daa3c13283ecf7fa06dcf01c43037ce3/diff:/var/lib/docker/overlay2/0606428afdfbffeb9fcff8444e33aa2e537a08116167f9070d4c62c5b08ffe66/diff:/var/lib/docker/overlay2/1b88b7b77a0148b33e8214078fafb130424bd5a522f5a3a8b1a19c32961768ad/diff:/var/lib/docker/overlay2/e6ba904feef718a403ccdde6dd3c045f6c869fdf63aa8c39a4472ca6aa1906e2/diff:/var/lib/docker/overlay2/6675bfb7bfd76f32db80e8a3064d499a82131b050d38ae8b59db229e305cd48b/diff:/var/lib/docker/overlay2/7bc5527bdce7da38608a27058d38715b610ddf881d5231af9e7efee0b840ad73/diff:/var/lib/docker/overlay2/9ab9c73888d10136dd2ce570f0ca6ccae41ce50430ed68c1e78b5c053ae2632f/diff:/var/lib/docker/overlay2/7d48d73a703fcbcba70be84317df320e77f2cfd834afa7d9b022a3e995e65dfb/diff:/var/lib/docker/overlay2/ca470e137838395eb2b5a08aecf2caac40ac60376b21821f46e169463f9b08c9/diff:/var/lib/docker/overlay2/160ce910c48d095167cc17c6e399ea66ae3763395917bdea56722d6d3d94a2e1/diff:/var/lib/docker/overlay2/c33a088b7d3424ef15280453df06ba813d55cf3fe5663a96f2477d6b13ce82cb/diff:/var/lib/docker/overlay2/88d400106dbc1b9791f2a3876c09a138790e203f26ed8c67f0ace70bf0b99a18/diff:/var/lib/docker/overlay2/f4ecd3e38234696fce61857ffb41226ba504b56606be0024364604d4e76b184b/diff:/var/lib/docker/overlay2/8b5c447cae1eaed18ea92382ff572f95c76262bede538cd455c4fafad0b3efb6/diff:/var/lib/docker/overlay2/95f529f60cf9fec90635e705c860f5b18aa7659421e186872c7fd985442a4a1c/diff:/var/lib/docker/overlay2/d1e15c3406e71ae5a67bb45b8e4de69bacad67d5b1a43adc03ff79cf84da5db0/diff:/var/lib/docker/overlay2/6f240c362aa60f094dd91b6e404167aab598439f6649cf29d34120e55a0f8645/diff:/var/lib/docker/overlay2/287d84f49c97c043c8e4b602ebf3a49a980ca5d0c93d70b3ed84da0ce9f294d5/diff:/var/lib/docker/overlay2/dda3faa1504dc3b9c86aa5c3a7bb30770d7a29d5722844352654727262b33734/diff:/var/lib/docker/overlay2/f3361b0bee89a772ec7d7c55a697660d77cd61595a315900e5549452fda9f529/diff:/var/lib/docker/overlay2/21a502e7c33776749921b56cfa29a9d2e79c034f4a6d60d4e51e448596b927d9/diff:/var/lib/docker/overlay2/797a1c48d4020104e5a2d679f9901adc1f661dcd8111e0a896cd5378a49c931a/diff:/var/lib/docker/overlay2/e77f8cf5c902b2716aa4da03226a313047b7c44bd090d76259ba7855645602e1/diff:/var/lib/docker/overlay2/0e941d8c5bb9e57ecf5df0ae25bf9981c9cd711a9baf8b27ab4757610fa4dc99/diff:/var/lib/docker/overlay2/f68f9133f25ecd953eff48652149758178094c802f18529ac43768e66767f9ef/diff:/var/lib/docker/overlay2/ed630e428aa14bae784e98058bcc8c580b6475bf71647ac0d49a91b9981b6dbf/diff:/var/lib/docker/overlay2/435d57dc5fce9126f303c3a620fd9c366815e8a35b5c5ca2e6e8c014dabc1251/diff:/var/lib/docker/overlay2/a89ee2e3e8aa602c9f995ea0f181c172da0dbb1ecd971892b5e7145cdc5753e5/diff:/var/lib/docker/overlay2/5de535384e36c6d1dbd16d610579643deda49b6935b56adf496e84fc39786b61/diff:/var/lib/docker/overlay2/54ce5ef0b9280fc0c016ba3a67f7492d103754adc1c1fca18b980e707961e060/diff:/var/lib/docker/overlay2/8a40e7d564918fb545d5978016776c4ea353737146901d134d4a372a1c3b28ca/diff:/var/lib/docker/overlay2/b13f00e8f4394669f881d47b864f14a3f7ae2fe084ca11f02cadfda618d329f0/diff:/var/lib/docker/overlay2/bfe87a0e6b6b404219b75eda507e63a7ba2db49a21411d3b4e8c3bd5864956a6/diff:/var/lib/docker/overlay2/023379d1e571c7695e8956cc97cceec593720f1d955174787ee51467529fdbf6/diff:/var/lib/docker/overlay2/cbc514c26fba91cfbe18db1687e90255c0d166a97cb37fbd3acd36f9362bcbe1/diff:/var/lib/docker/overlay2/506e38af937b17aca134e1fc1e4aff24012734e8f6f4674c899f96ae31360cc1/diff:/var/lib/docker/overlay2/6d484fc1cf19c5629b9e7d7aa69b5aa0d507501fb42a3185a4f698ee50b0b2f9/diff:/var/lib/docker/overlay2/e1b108443c26f3a511f480e1686fe2b3e111716563760c0370fe15f70fcd4b8f/diff:/var/lib/docker/overlay2/cd1f49902eee86653a38f7214a0187c93c1630bef3eb6bebe2716bbebfa851eb/diff:/var/lib/docker/overlay2/370aa53e50d4cd5065f45335aa6402cf9a825f9b796f1f07f64f76f3250cd886/diff:/var/lib/docker/overlay2/bf4a21ef7b1307b7fb80d8e565a5f3634f300c74c97db095ee4cc5585bb9036b/diff:/var/lib/docker/overlay2/2614ecdb88a6b86470717d7670c3dbcb95262fd392ebd6368c1d755a8708dc74/diff:/var/lib/docker/overlay2/c0a1a9f21cea72572df5a21ff3673f3477f45a60a8365d7fb8e140d46750a069/diff:/var/lib/docker/overlay2/b9366302c72f6a6334e304ad702dc2db1b39c3b7d49ec2526dd073a2b54b0eb9/diff:/var/lib/docker/overlay2/d33cb784414fa4c6eaddbc4ab3dcb620e74f57d9bcf69b0ad0a5b57aebb8542c/diff:/var/lib/docker/overlay2/01f4d60ba0891523a1dcb899b262fdce0800a2537ac348dab1783c0262b8d996/diff:/var/lib/docker/overlay2/0ef1821409a93580f740dc912d39de52b15ed3b762f8cd80989c44dc9b156e54/diff:/var/lib/docker/overlay2/8138199d69857c1d96b4e0e9451d08d885ba5032bd0b8ed537d4747754046c12/diff:/var/lib/docker/overlay2/af249269c9bf8ab379688ac10c37b3f80557ae5e37377dc78b4853c4a0aed749/diff:/var/lib/docker/overlay2/5b0d709f9608e33c06bed35653a7fc384f5b310d2cd280920e77682c2eede20c/diff:/var/lib/docker/overlay2/7b35d2db18bf8d52716df1d5dc89fa4fe0b75c55ca4f77be68e64d399853f812/diff:/var/lib/docker/overlay2/6d53a3f6c8dbc35ce010c02eb29876107989b3c7c466245f90e6a161cbc3af99/diff:/var/lib/docker/overlay2/7326a8628275835815d8b795836ed9d5e4da1c5d1828ad8d5b9ca264c79dfe23/diff:/var/lib/docker/overlay2/799fcef6f5fd5ba7434a54cc200600b62be46ddbbd92539d5aaad3e354525418/diff:/var/lib/docker/overlay2/97a9396838d7bd804902cd49965eff5ee7cdba5b016e9f6f186a05af0d631ca9/diff:/var/lib/docker/overlay2/bfa2523624a319d4ecdb4c516b426156fc37a9fdd9f85408d0464db20488e798/diff:/var/lib/docker/overlay2/334304eba9f8bd81019d10575921e39222ad46b859f05107238105a378601a33/diff",
                "MergedDir": "/var/lib/docker/overlay2/b9d6162c2a5cd7a5845100dff17c688f2d9bd51cc89a752826464ef98109be07/merged",
                "UpperDir": "/var/lib/docker/overlay2/b9d6162c2a5cd7a5845100dff17c688f2d9bd51cc89a752826464ef98109be07/diff",
                "WorkDir": "/var/lib/docker/overlay2/b9d6162c2a5cd7a5845100dff17c688f2d9bd51cc89a752826464ef98109be07/work"
            },
            "Name": "overlay2"
        },
        "RootFS": {
            "Type": "layers",
            "Layers": [
                "sha256:be96a3f634de79f523f07c7e4e0216c28af45eb5776e7a6238a2392f71e01069",
                "sha256:df54c846128da3c71cc11b2150a3df39ec86fb170e299765daf6bb016a0705c2",
                "sha256:47ef83afae74745639f6738a05fe5320fcfca9e6c7765fba4f25e270bc0df9dc",
                "sha256:1251204ef8fc20da275e09f6e3ab9205421d4ff34732f2d50a1d3e86d2995edd",
                "sha256:a053d5fbf6214982010835a80f01dd15ba89a6ac6278d92d992ff98a415e23cb",
                "sha256:896120a5709af8bb8dd29dbd61d67bbf6c83ea3e9c6034e5585a00afc625df8d",
                "sha256:6d357a586d6ccd28a63de1569758ef7380ec683ecae91dcb8f05b0f7b235d35e",
                "sha256:3b9d7320fc61ddf0d42916e1fdc9a880cdf5133607cd993ae3a923af4b13d20e",
                "sha256:ad6a695ffdcf3f0517e3f745971d1acd0af7f95bd4a05e4150378999e1439b53",
                "sha256:a93ae153f82719c505090c79fcf8df22ada144f9d613ee5caa46501a90d36f63",
                "sha256:75c6b9b57da528d2ef7c9b26a40d387043e77c42e6bc8a58461fd5bf21ef3f05",
                "sha256:c8f58786c92d7bf9c1bbd54dc3b0267c0b5788702c38675b1a84b4a6b9c2cb89",
                "sha256:9fbd29c4c152460c12fbebd0c67f1c6154b2775d28154de707cff7ac30ef9697",
                "sha256:1d7efc2c8f0f9d66a2970b22c9066d88e3301fe5514b6df2c3902550582db928",
                "sha256:13715645ee31255727d199d8acef1aeaf137938c5c9dd6a4531022f234a1998f",
                "sha256:2890d646fe2714a05d8ad7c7c5e0112d5361925acd4a71e17ff325c190a9fdda",
                "sha256:f213c5242c22e2696b26e3909c893bfa8060dac9893d3067e7cd79270c0f341d",
                "sha256:150cb61e73b4352c40848832662527e115664be3bfa9840f671bf5f8be4e9e73",
                "sha256:2f6bc9fb50d11447c111e9319c20d5ecb5472ab56b196004d32e91928744f35d",
                "sha256:c4b02bc122639e0f3afd2a40ca935201485fdf3c9ddf8a681994000707ffe141",
                "sha256:9a124479462c6fc3351d81b410968c99d978b845204bb59b0202688a7031f09e",
                "sha256:b478792a072b6440db7886f7223fbb3b0a9a033e3f11b034f85e8c05c12331eb",
                "sha256:420cff1d9744638efa1b6810b2db057f6b13074d6354ea34c286552dad5d436d",
                "sha256:eb78a0f38d49ec1676c8556aa96e472964a5c78129d1b99b6df7bf3bd12b1414",
                "sha256:74c179e49161fd5601fd3a71a700869f986b95e332890f1619728a2699e0adad",
                "sha256:8d8f9f5360519c602f00dbcc9655b5d5863ca7bb868f557e6ae73b3243d5caa3",
                "sha256:841e4cccfe92578e3733911c1c3782b81510e83964a4d97aa9f116115fdf35e9",
                "sha256:45b46f8f42c9e331f92974b61651f81a8b44033140ee8316e91ecefdf5f3370c",
                "sha256:7913ba8ad57039928a3920918fd99910de3e073285f5e2086148f321dbc19bcb",
                "sha256:bd8e37fb43eb092cff781c2514545ebc4e36641f6960e98af81d413fbb12b2bf",
                "sha256:6ec446855e77593c7e7cfed8acc2c11f282a42cfeee16807cd7b2f8f323ecdc6",
                "sha256:5f70bf18a086007016e948b04aed3b82103a36bea41755b6cddfaf10ace3c6ef",
                "sha256:f107f8f5827cfcecbec926f57547cdd2fb1b600922e9a90968443977d793ff4e",
                "sha256:463f52e45978fb8c960d174a99717f2ebbc2b1097e12fff55643940009d06780",
                "sha256:a5be4322adc9213d331a59ef93c49fafa73839cbff416fd102cdd32521d30ded",
                "sha256:61b22779b2eebe18d35adea57738ba579a0eeb35e8e60543793af1a05cd4d11e",
                "sha256:28beccf98a2f341d5507dbc255332048bb7b2f5da77281280881e89c15cb29a1",
                "sha256:0088573b023dcfac34146c04a5cb18f90070972c09a260d25daf1919555dba57",
                "sha256:53a4891e2cfc4e6a8ba1285f9d207fca15ee770e7f2dc3668d83c5e7f630b967",
                "sha256:5ce033a6b115db089d8a47e5403b64a903df5ea236d660ff69ea55bda089a44e",
                "sha256:7e336226764c97a914cfc33d2f8f5129668477917e1aa8e7f4d7943a02befdd5",
                "sha256:f5f5669d07001e7e400fd76b2643692e887682695a833708daafc40243663dc4",
                "sha256:944cd74946ca0a3b223ffcdf0ddb8b6f5afe1488a0619f387ed5211fcf42da63",
                "sha256:79078bdc1d93f0d30de82c83fe7ccdbe9a2b9175f6bc18fe216343357fd16092",
                "sha256:0e1e0bf1e7371831e0dc9e32b1a3b762ad6b627c44ba3c4c547cc687d43e9c67",
                "sha256:76712bd4d3dd643a8227af4531aed8c8c425ea527a6a1c8ea2a775e5fc6733cb",
                "sha256:4040831ea2c12db54da5577d0c41a64c44a98e61e4cfc9eb47c27df2e7f4c514",
                "sha256:0053b2e39ca41840516dc3ddbe24a59f71b3102444567406107dd3e6ebe3a87a",
                "sha256:23a055d149b18f6080d65d6d90169d1f636f4dcfef30b6cf61f939d653884fd8",
                "sha256:6c0e0b35b0b6a335ce2ca1362908e4f150c12a688d1ddd5291cfb69b7feef21f",
                "sha256:27e043d9c9226ad6b6d0de87a02655c7d4e92137033a889f5a0aa9d72a1cfd23",
                "sha256:c6c239855185fcb7ac824415a4b3d9b18dd4571c3638ea53471479a42b16c8cf",
                "sha256:ad11a066dfbcb97b46dca7096ea1db2e0fd9290bac65bc645cda852c9b78c06b",
                "sha256:6d512f7f26a702bbd2914dbd02e70d7cbea1f63aa5ba2c5c8cd842484d549a27",
                "sha256:f93bd956435f03f33fe5741ec04d14ae3ebd7938fc6f36073f60e088f30e0402",
                "sha256:4066538d80ac24c37199b2b8c85248408801b16982c899b33d173c6f4c95a7b0",
                "sha256:96831b312a4767e13e6c4732da00e43dc639c03828ca78c9b415ce3fc527d8dc",
                "sha256:1139a2936a67cbafd148f6411fe43db97351beb34122070cb98d65c10d2f52ad",
                "sha256:9881e91ef6568be320f7e53d7261ca58dda0280ef792d57bd6738415465e600a",
                "sha256:04a6b8766533af43ee2c5de458448b7ab0b22544d9c6935b868453770f3ef86d"
            ]
        },
        "Metadata": {
            "LastTagTime": "0001-01-01T00:00:00Z"
        }
    }
]
